







Multicore architectures are changing the way we write programs.
Not only are all computational devices
turning multicore thus becoming inherently concurrent, 
but tomorrow's multicore will embed a larger amount of simplified cores to better handle energy while 
proposing higher performance, a technology also known as \emph{manycore}~\cite{Borkar2007}.
Thus in order to take advantage of these resources programs must be written so
that they can execute concurrently.
Interestingly  enough,  
it is important to also observe that the recent advent of multicore 
architectures has  given rise to what is called the {\it multicore  
revolution} \cite{HL08} that has  rang the revival of concurrent programming. 


\section{Lock-based concurrent programming}
% A   {\it concurrent  object} is  an   object that can be   concurrently  
% accessed by different processes of a  multiprocess program. 
%
It is well known  that the design of a concurrent program is not an easy
task.
Given this, base synchronization objects have been defined to help 
the programmer solve  concurrency and process cooperation  issues. 
A  major milestone in this area, which was introduced 
more than forty years  ago was the concept of {\it mutual exclusion} \cite{D68}
that has given rise  to  the  notion of  a  {\it  lock} object.    
A lock object provides the programmer with two operations (lock and unlock)
that  allow a single process at a time to access a concurrent object. 
Hence, from a  concurrent object point of view,   the  lock associated with
an object allows transforming  concurrent  accesses on  that object  
into sequential accesses.
% Given that a persons though process happens sequentially this way of using locks
% has helped them become the most popular method of synchronization for programmers
% writing concurrent programs.
In addition, according to the abstraction level
supplied to the programmer,  a lock may be encapsulated into a linguistic 
construct such as a {\it monitor} \cite{H74} or a {\it serializer} \cite{HA79}
giving the programmer additional operations.
The type of synchronization admitted by locks is often referred to as \emph{pessimistic}, 
as each access to some location $x$ blocks further accesses to $x$ until the location is released.
Unsurprisingly given that
a person's thought process happens sequentially
and that this concept of mutual exclusion is a straightforward way to
conceive of synchronization/concurrency,
locking is the by far the most widely used abstraction to
implement concurrent algorithms.

Unfortunately locks have several drawbacks. One is related to the  granularity
of the object protected by a lock. More precisely, if several data items 
are encapsulated  in a single  concurrent  object, the
inherent parallelism  the object can provide 
can be drastically reduced.
In a bad case all threads except the one owning the lock could be blocked waiting
for the lock to be released, resulting in no better then sequential performance.
This  is for example the case of a queue 
object for which concurrent executions of enqueue and dequeue operations 
should be possible as long as they are not on the same item.
Using locks in such a way is often referred to as ``course-grained''.

Of course in order to improve the performance of course-grained locking
the first solution that comes to mind would be to simply
use a finer grain.  For example one could consider
each item of the queue as  a concurrent object with its own lock,
allowing the  operations  enqueue  
and  dequeue  operations to execute concurrently.
Unfortunately it is not that simple as implementing operations using
fine grained locking can  become very   difficult  to  design and implement
correctly.

The most common difficulty associated with using fine grained locking
is avoiding deadlock.
Deadlock occurs when a process $A$ wants to obtain a lock that
is already owned by process $B$ while concurrently process $B$ wants
to obtain a lock that is already owned by process $A$ resulting
in neither process progressing.
In order to avoid deadlock locks are often acquired in a global order,
but this may result in locks being taken more often and held longer then necessary.

Other problems with locks can occur when a process holding a lock
is descheduled by the operating system while a live process is trying to
access the same lock (sometimes called \emph{priority inversion}.
Further problems can occur if a thread crashes or is stalled while
holding a lock.

Another important drawback associated with locks lie in the fact that 
lock-based operation cannot be easily reused~\cite{HMPH05,GG11}.
Consider the queue example, a programmer using a lock based queue
might want to create a new operation that inserts two items in the queue
atomically.
If the queue is implemented using fine grained locking then creating this operation
would likely require the programmer to not only have extensive knowledge of the current
queue implementation, but to also have to make modifications to the entire implementation.
If a single lock is used for the entire queue object then this operation can be implemented
easily, but any performance gain due to concurrency is lost.
This process of reusing operations is often referred to as composition.


\section{Alternatives to locks}
Given that programming using locks
is no simple task
we must ask the question:  how to  ease  the  job of  the programmer  to write
concurrent applications?
This is neiher a simple question to answer nor a question that has one correct answer.
Due to this much research has been done from providing the programmer with access to additional
efficient low level hardware operations, to providing high level abstractions, to completely
changing the model of programming.
We will very briefly mention some popular examples before introducing the solution that is
exaimned in this thesis (namely software transactional memory (STM)).

\paragraph{Non-blocking concurrent programming}
Non-blocking algorithms \cite{GC96} have been introduced as an alternative to using
locks in order to avoid some of the scalability and progress problems of locks.
These algorithms are implemented using powerful system level synchronization operations such
as $compare\_and\_swap$.
There have been many efficient and scalable non-blocking data structures proposed
\cite{Mic02,ST04,Val96,FR04,Fra03}.
Unfortunately such algorithms are known to be extremely difficult to implement
and understand.
Simply implementing a concurrent non-blocking version of a sequential data-structure
has been enough to publish papers in top research publications, showing that
non-blocking algorithms can be very difficult to get correct.
As a result, non-blocking operations can help overcome some of the specific problems of locks
but make no considerations about the difficulties of writing correct concurrent programs.


\paragraph{Libraries}
A different partial  solution to making concurrent programming easier consists of providing 
the programmer with an appropriate 
library where  he  can  find  correct  and  efficient concurrent implementations  of  
the most popular data structures (e.g., \cite{HS08,MS96}). 
For example Oracle's Java SDK provides several concurrent implementations of different abstractions in its
\emph{java.util.concurrent} package, including several queue implementations,
skip lists \cite{Pug90} implementing the set and map abstractions, a hash map, among others.
Albeit very attractive, this approach does not solve entirely the problem  
as it does not allow the programmer to define  specific concurrent executions 
that take into account  his particular  synchronization issues,
even simply composing several operations of the provided implementation
to create a new operation is usually not possible using these libraries.
A libraries' use is then restricted to the specific functionality of each abstraction's implementation,
leaving the responsibility of dealing with any separate synchronization to the programmer.

% \anote{Should mention more things here???}

\section{The Software Transactional Memory approach}
The concept of {\it Software Transactional  Memory}   (STM)  is  a possible answer  
to   the  challenge of concurrent programming.
Before describing the details, let us first consider a ``spirit/design philosophy'' that has helped give
rise to  STM systems: the notion of 
{\it abstraction level}.
More precisely,  the  aim of an increased abstraction level is   to allow  the programmer  to  focus and
concentrate only  on the problem  he has to
solve and not on the base machinery needed to solve it. 
As we can see, this is the approach  that  has   replaced assembly languages  
by  high level languages and programmer-defined garbage collection 
by automatic garbage collection.
In this manner STM can  be seen as a  new concept
that takes  up  this challenge when considering synchronization issues.

The way transactional memory abstracts away the  complexity associated with 
concurrent programming is   by  replacing locking  with  atomic
execution units.
Unlike using locks where a programmer might use several locks
throughout his operations, when using transactional memory
a programmer just needs to define what sections of his code should
appear as if they execute atomically (i.e. all at once, leaving
no possibility for interleaved concurrent operations).
The transactional memory protocol then deals with the necessary
synchronization to ensure that this happens.
A programmer could think of it as using a single global lock
where ever he wants to perform synchronization between processes.
In  that way, the programmer has to focus on  where 
atomicity is required and  not on the  way it must be realized. The aim of
an STM system is consequently  to  discharge the programmer from the direct 
management  of  the  synchronization  that  is entailed  by   accesses   to
concurrent  objects.  

More explicitly,  STM  is a middle-ware approach that provides the 
programmer  with the {\it transaction} concept (this concept 
is close but different from the notion of transactions encountered in 
database systems \cite{FFGH08,HCUAGSV07,HL08}).
 A process is designed as 
(or decomposed into)  a sequence of transactions, with each transaction 
being a piece  of code that, while  accessing  concurrent  objects, 
always  appears as if it was  executed atomically
% \footnote{Actually,  
% while the word {``\it transaction}'' has historical roots, it seems that 
% {``\it atomic procedure}'' would be more appropriate because 
% ``transactions''  of STM systems are  computer science objects 
% that are different  from database transactions.  We nevertheless 
% continue using the word  {``\it transaction}'' for historical reasons.}.
The programmer then must state which  units of computation
have  to be atomic.  He does not have to worry about the fact that the 
objects accessed by  a transaction can be concurrently accessed. 
Therefore the programmer is not concerned by synchronization
except when he defines the beginning and the end of a  transaction.
It  is then the job of the 
STM system to ensure that transactions are executed as if they were atomic using low level synchronization
operations such as $\lit{compare\&swap}$ or even other abstractions such as locks
(note that all these details are hidden from the programmer as he only has access to the interface
to the STM which allows him to define atomic computation units).

Another important advantage of using transactional memory over locks it that a transactional program
can be directly reused by another programmer within his own code.
Hence a programmer composing operations from a transactional library into another 
transaction is guaranteed to obtain new deadlock-free operations that execute atomically.
Further promoting the ease of use of transactions, several studies~\cite{PA11,RHW10}
have been performed that find that (under the parameters of their studies) users can create concurrent programs
easier when using transactional memory instead of locks.




\section{Details}
\label{sec:details}
The notion  of   transactional  memory  was
first   proposed  nearly twenty years ago by Herlihy  and Moss 
as an abstraction to be implemented in hardware and be used in order to easily 
implement lock-free concurrent  data structures  \cite{HM93}.  It  has  since  been 
first implemented in software  by Shavit  and  Touitou   \cite{ST97} and, partially thanks
to the multi-core revolution,  has
recently gained great  momentum as  a promising alternative  to locks in
concurrent programming  \cite{FFGH08,HCUAGSV07,LK08,R08}.
Especially in the research community transactional memory has been a very hot topic with hundreds
of papers being published, this section will give a very brief overview of some of that research
in order to help explain STM.


\subsection{Programming}
As an abstraction designed to make concurrent programming easier, transactional memory needs a
simple and precise interface for programmers to use.
In order to actually define transactions in code, the most common
approach is to surround the code by some keywords that indicate the beginning and end of a transaction.
For example the programmer might just enclose his transaction using the \emph{atomic} keyword:
$$atomic\{\ldots\}$$
The code within this block will then be treated as a transaction and appear to be executed atomically.
In an ideal world this would be all that a programmer would have to know before starting to use
transactional memory, but unfortunately as will be shown in this thesis, it is much more complex than this
and there are many other things that the programmer must consider.


\subsection{Memory access}
Within a transaction a programmer will perform reads and writes to memory.
Certain of these reads and writes will be to shared memory that is also visible to other transactions
being executed by other processes in the system.
In this case these memory accesses must be synchronized by the STM protocol.
Each of these reads perform a $\lit{transactional\_read}$ operation with each writes performing a $\lit{transactional\_write}$ operation.
These operations are defined by the STM protocol and usually require executing several lines of code.
In addition to shared accesses, some memory accesses within a transaction might be to local memory
(memory that is only accessible by the current process),
as such this memory does not need to be synchronized (although it needs to be reinitialized when a transaction is
restarted after an abort [aborts are described in the following section]) and can therefore be performed more efficiently then shared accesses.

Deciding which accesses should be treated as shared and which others should be treated as local
can either be done by the programmer or done automatically by the system.
Of course a solution that requires the programmer to define this makes using an STM more complicated, but on
the other hand determining them automatically can lead to more accesses being declared as shared then necessary
causing increased overhead during execution.
Doing this efficiently is no easy task, \cite{DFGG11} discusses some of the difficulties with STM code complication.
and in \cite{1133985} an efficient STM is designed with optimizations for their JIT complier to lower the overhead
of shared memory accesses.

A further complication with shared memory accesses is defining what happens when memory is accessed both inside and outside
of transactions, i.e. transactionally and non-transactionally.
There have been several proposals detailing different ways to deal with this such as \emph{strong} and \emph{weak isolation} \cite{shpeis07}
and \emph{privatization} \cite{spear:privitization:podc:2007}.
Chapter \ref{chap:SI} looks at the problem of memory access in more detail.

\subsection{Abort/Commit}
For an STM protocol, a solution in which a single transaction  executes at a time
trivially implements transaction atomicity but is irrelevant from 
an efficiency point of view. So, a STM system has to do ``its best'' to 
execute and commit as many transactions  per time unit as possible
(a concept sometimes referred to as \emph{optimistic synchronization}), 
but unfortunately, similarly to 
a scheduler, a STM system is an on-line algorithm that does not know 
the future. Therefore, if the STM is not trivial (i.e., it allows several transactions 
that access the same objects to run concurrently),  
then conflicts between concurrent transactions may require the system to abort some transactions in order 
to ensure both transaction  atomicity and object consistency.
Hence,  in  a
classical  STM system  in order to ensure safety  there    is  an    {\it   abort/commit}    notion
associated   with transactions. 
Abortion is   the price that has to  be paid by transactional  systems to cope 
with concurrency in  absence of explicit pessimistic synchronization mechanisms
(such as locks or event queues).
From a programming point of view, an aborted transaction has no effect.
Usually it is then up to the process that issued an aborted transaction to re-issue it or not; 
a transaction that is restarted is considered  a new transaction. 
Unfortunately this does not mean that the programmer can be ignorant to the concept of transaction aborts.
Most STM systems require the programmer to at least be aware of aborts, if not responsible to take
some action to certain cases of aborts.
The problem of aborted transactions and how a programmer must deal with them is discussed in detail in chapter
\ref{chap:UC}.



\subsection{Correctness}

Without a proper consistency or correctness criterion the programmer is lost, these criterion must ensure that transactions execute
atomically and prevents the programmer from having to worry about inconsistencies that might occur otherwise.
STM consistency criterion define when a transaction can be committed or when it must abort. 
Interestingly, choosing a consistency criterion for memory transactions is different than from database transactions
and even different then other concurrent objects,
for example a common consistency criterion for database transactions is \emph{serializability} \cite{P79}.  
Serializability guarantees that every committed transaction happened atomically at some point in time,
 as if they were executed sequentially.
The real time order of execution does not need to be ensured,
a transaction that took place long after a previous transaction committed can
 be ordered before the other, as long as the ordering creates a valid sequential execution.
\emph{Lineraizability} \cite{HW90}, the most common criterion used for concurrent objects, is stronger than serializabilty by
adding the condition that transactions must be ordered according on their occurrence in real time.
Importantly these conditions say nothing about aborted transactions.
A transaction must abort if it has an \emph{inconsistent} view of the memory or set of data
meaning that there is no time where this transaction could have been viewed as if it was executed atomically when considering
the state of memory created by previously committed transactions.
Commonly, in database
systems a transaction can run without causing harm in the system even if it 
has an inconsistent view of the data as long as it eventually aborts.
Unfortunately, in transactional memory this is not always the case.
% \anote{Should include this example??}
Consider the following example:  There are two transactions $\ms{T_1}$, and $\ms{T_2}$, and three 
shared variables $\ms{X}$, $\ms{Y}$, and $\ms{Z}$ all initialized to $0$.  Transaction $\ms{T_1}$ performs
the following operations, first it reads $\ms{X}$, then it reads $\ms{Y}$, then it sets $\ms{Z}$ to 
the value of $\frac{\ms{Y}}{\ms{X}}$, before trying to commit.
Transaction $\ms{T_2}$ writes the value $1$ to $\ms{X}$, writes the value $1$ to $\ms{Y}$, 
then tries to commit.
It is obvious that any transaction reading the consistent values of $\ms{X}$ and $\ms{Y}$ 
will read them as either both $0$ or both $1$.
Now consider the following execution pattern, where transaction $\ms{T_2}$ commits successfully:
$$begin\_transaction_{\ms{T_2}}(), begin\_transaction_{\ms{T_1}}(), X.read_{\ms{T_1}}() \to 0, X.write_{\ms{T_2}}(1),$$
$$ Y.write_{\ms{T_2}}(1), try\_to\_commit_{\ms{T_2}}(), Y.read_{\ms{T_1}}() \to 1, try\_to\_commit_{\ms{T_1}}()$$
Now transaction $\ms{T_1}$ will access an inconsistent state of the data, reading $\ms{X}$ as
$0$ (because $\ms{x}$ was read before $\ms{T_2}$ committed) and $\ms{Y}$ as $1$ (because $\ms{Y}$ was read after $\ms{T_2}$ committed).
%Since $\ms{A}$ now has an inconsistent view of the memory, when it performs the division 
Now when $\ms{T_1}$ performs the division
$\frac{\ms{Y}}{\ms{X}}$, a divide by $0$ exception is created possibly resulting in undesirable
 behavior such as crashing the program.
Divide by zero exceptions are not the only possible undesirable behaviors that can
 be caused by reading inconsistent memory values, some other possible problems include 
infinite loops, and accessing invalid pointers.
In order to deal with this many STM implementations abort a transaction before it
 can access an inconsistent view of the memory, but it depends on the consistency criterion.
The differences between database and memory transaction correctness conditions is examined in more detail in \cite{AH12}.
Chapter \ref{chap:VWC} looks at the problem of correctness in transactional memory in more detail.


\subsection{Nesting}
% Part of the difficulty caused by programming with locks is that they are not composable.
% It is often not obvious and not even always possible to create new code using locks that
%  reuses code that also uses locks and still perform the correct function while avoiding deadlock.
One of the suggested benefits of writing code using transactions is that they be composable,
 which could be a huge benefit over locks in terms of code simplicity and re-usability.
Still it is not obvious how implement composability correctly and efficiently in transactional memory.

The term \emph{nesting} is used to describe the execution of transactions within other transactions.
Different way of implementing nesting have been studied with varying properties.
The simplest way to implement nesting is called \emph{flattening} \cite{ALS06},
% \anote{Where is this citation from??}
in this model a nested
 transaction is combined together with its parent, so it and its parent execute as if it were a single transaction.
This is nice because it is simple and it is composable, but it creates larger and larger transactions, limiting performance.

A slightly more complex model \emph{closed nesting} \cite{1133985,Mos81} allows a transaction $T_C$ to run as a separate
 transaction within its parent $T_P$, but when $T_C$ commits, its changes are only visible 
to $T_P$ and not visible to the rest of the system until $T_P$ itself commits.
Running $T_C$ as a separate transaction allows it to abort itself without aborting $T_P$, 
hopefully increasing performance over the \emph{flattening} model.
By not committing $T_C$'s changes to shared memory until $T_P$ commits, it prevents there 
from being consistency issues or roll backs of shared memory in the case that $T_P$ aborts after $T_C$ commits.
% \cite{1133985} givens an implementation of closed nesting is given for the Java language
%  along with some additional mechanisms that can be used when a nested transaction retries or aborts.

A more complex notation of nesting is \emph{open nesting} \cite{Mos06} which allows for nested 
transactions to write to shared memory immediately upon their commit, not waiting until their parent commits.
The main advantage of open nesting is performance.
Like closed nesting it has the 
advantage that if a nested transaction aborts, it does not require the abort of its parent transaction.
In addition open nesting has the advantage that the memory locations accessed
 by a nested transaction need not be included with the parent transaction when detecting conflicts. % with concurrent transactions.
% \anote{remove example??}
For example consider a parent transaction $T_P$ that accesses memory location $X$ with a 
nested transaction $T_N$ that accesses memory location $Y$, and in addition there exists a separate transaction $T_S$ that also accesses $Y$.
Now take the execution where $T_P$ starts, then within $T_P$, $T_N$ starts and commits, following this $T_S$ starts 
and commits, finishing with the try to commit of transaction $T_P$.
In an STM implementing open nesting $T_P$ is able commit because even though its nested transaction $T_N$ conflicts with transaction
$T_S$, in this example $T_N$ has already committed before the start of $T_S$, creating no conflict. 
Alternatively, using closed nesting and flattening, $P$ might have to abort because $N$ has only committed
 within $T_P$ and not to shared memory, resulting in a conflict between $T_P$ and $T_S$.
For more details, \cite{Mos06} gives a comprehensive overview of open nesting.
Allowing a transaction to commit to shared memory from within a transaction 
obviously violates the idea that everything within a transaction is executed atomically,
possibly increasing performance, but unfortunately also increasing the difficulty of writing
correct concurrent programs using transactions.
Additionally, in order to deal with open nested transactions, a new consistency model has to be considered, one such model, \emph{abstract} serializability,
is described  in \cite{NMA+07}.

% In open nesting handling the situation where a parent transaction aborts after a nested
%  transaction has committed becomes very difficult.
% It is not sufficient to just roll back the nested transaction as that could lead to
%  inconsistencies with other transactions that had committed after the nested transaction committed.
% In order to deal with this \cite{NMA+07} introduces a set of extra mechanisms that
%  a programmer can use, but this also introduces quite a bit of difficulty for the 
% programmer, and if used incorrectly can cause deadlock.
% Because of these difficulties, they \cite{NMA+07} conclude that open nesting is only
%  useful for expert programmers, but it allows them to create efficient libraries of
%  data structures and algorithms that can benefit largely from open nesting.
% These libraries can then be reused by non-expert programmers when writing
%  transactional code where they themselves cannot create open nested transactions.


\subsection{Implementation}
This next section will look at how to to actually implement these things, and some
 of the difficulties that go along with this.
Importantly, even though there are many ways to implement software transactional memory, there is no clear ``best''
method, in \cite{1123001} they 
perform benchmarks on many of these options and come conclusions as to which choices are
 preferred, but it is not clear that their decisions are conclusive.


\paragraph{Read and write sets}
In a system where multiple transactions are executed optimistically
in order to ensure that a transaction execute on a valid state of memory and satisfies
a consistency criterion it must perform some sort of validation.
Traditionally this process of validation requires keeping what is called a \emph{read set}.
A read set contains the set of all memory locations read so far by a transaction as well as some additional information
(depending on the implementation) on these locations such as the values read.
This read set is then validated based on some event such as when a new read is performed or when a transaction tries to commit,
 ensuring that the locations read so far are still valid.

In addition to a read set, a \emph{write set} is also maintained by a transactions, keeping track of all the locations
written so far by the transaction.
Write sets are necessary due to the fact that a transaction might abort.

\paragraph{Write Buffering vs Undo logging}
When performing a write within a transaction, to the rest of  the system the value
 written must not known until the transaction is guaranteed to commit,
i.e. an aborted transaction must not effect the state of memory.
Traditionally there have been two ways of keeping track of writes before they have committed in memory.

In an implementation that uses \emph{undo logging},
% \anote{Citation?}
the transaction performs its write
 directly to the shared memory, and then in case of an abort, the transaction must
 rollback the state of the memory to where it was before the transaction performed its first write.
In order to prevent other transactions from writing to the shared memory concurrently
 or reading a value that could be rolled back, a transaction will use some sort of locking mechanism of each piece of memory before it writes to it.
This is usually implemented as \emph{visible writers}, which are described later in this section.

In an implementation that uses \emph{write buffering}
% \anote{Citation?}
when a transaction wants to perform
 a write to a shared memory location first it will make a local copy of that variable only visible to the transaction.
Any subsequent writes this transaction does will be preformed on this local copy,
 and if the transaction commits successfully then the value of the local copy will then be written into the shared memory.

There are some advantages and disadvantages to both solutions \cite{1123001}, and depend on how the rest of the 
protocol is implemented.
Often one type performs better then the other depending on the workload.

% Undo locking is nice because it does not have to keep track of local memory for writes,
%  and when write transactions committ it does not have to copy the values from local to shared memory.
% Write buffering is nice when transactions abort because it does not have to perform roll back on the shared memory,
%  and it allows the posibility to use invisible writes which are described later in this section.
% Different STMs choose to use one or the other, given that write buffering can implement
%  invisible as well as visible reads it has been implemented in many TMs, but other then this there 
% is often no definite or obvious reason to choose on over the other, or why one is better.
% \textcolor{Red}{What limitations does one have over the other?}


\subsection{Conflict Detection}
The definition of a conflict in transactional memory is straightforward, two 
transactions conflict if they execute concurrently and both access the same 
shared memory location with at least one access being a write.
Given this definition we can separate conflicts into three specific types based
on the order and types of operations that caused the conflict, more precisely we have
read/write, write/read, and write/write conflicts.
% Earlier in this survery in the section on liveness it was shown that deciding
%  what to do after detecting a conflict is no easy task.
% This section will discuss some of the ways transactional memory implementations
%  detect conflicts, and like conflict resolution, there is no simple answer to conflict detection.
Once a conflict happens, the system must deal with it in some way in order to ensure
safety and progress, possibly aborted one or both of the conflicting transactions,
this can done directly by the STM or a contention manager \cite{HLMS03} can be called.
Many different solutions for detecting and dealing with conflicts have been proposed and depend
on the STM protocol.

\paragraph{Visibility}
How conflict detection is performed depends on how reads and writes are implemented.
Transactional reads and writes can either be \emph{visible} or \emph{invisible} \cite{IR09}.
When a transaction performs an invisible read or write it does not perform any 
modification to shared meta data, so no other transactions are aware that it has performed the read or write.
In a visible implementation, the transaction writes some 
information to the shared meta data (usually adding its identity to the list 
of transactions that have read that memory location), allowing other 
transactions to be aware that this read or write has occurred.

Invisible reads have the advantage of not having to write to shared data, 
which can become a point of contention at shared memory locations that are accessed frequently.
This problem of contention can be especially worry-some for read dominated 
workloads because contention is being introduced when there are no conflicts and can limit scalability.
The principle disadvantage of invisible reads is that  \emph{validation} is required
 each time a new location is read or before committal in order to ensure an inconsistent view of the shared memory is not observed.
With visible reads, when a location that has been read gets overwritten
 by a writing transaction a contention manager is called, so validation is not needed.

% While it is fine to have mulitple readers for a memory location,
%  there can only be one writer per location, so visible writes are 
% usually implemented by acquiring a revokable lock.
% A possible disadvantage of invisible writes is that whenever a transaction
%  performs a read it has to perform a write set lookup.
% Meaning that the implementation has to check if the value read should be 
% loaded from shared memory or from a local copy, this is usually done by 
% traversing the local set of writes that the transaction has done so far, causing overhead.
% In order to get around this, in \cite{1504199} they use a hash table to 
% map addresses to indexes in the local write set.
% They show this gives negligible overhead for write set lookup when comparted to visible writes.

% \anote{Should clean up this section}
\paragraph{Eager vs Lazy}
There are two basic concepts for detecting conflicts between transactions, \emph{eager} and \emph{lazy} \cite{HLMS03}.
While precisely how eagerly a conflict is detected depends on the specific TM implementation, here we will
we use the term eager to describe conflicts that are detected before either of the conflicting transactions has
reached the committal phase and the term lazy to describe conflicts that are not detected until after one of
the conflicting transactions starts committing.
The choice of visibility for the read and write operations of an STM implementation directly effect the
possibilities of the eagerness of detection.
% An eager scheme detects conflicts as soon as they happen, while a lazy scheme detects conflicts at commit time.
% Write/write, read/write, and write/read conflict detection can be eager or lazy.
%Depending on which combination of these is chosen makes an impact on many different parts of a TM.

\paragraph{Eager}
%An implementation can detect read/write, write/read, and write/write conflicts eagerly.
Eager conflict detection obviously requires that an implementation use visible operations.
Specifically, eager read/write conflict detection requires that the implementation use 
visible reads while eager write/read and write/write conflict detection requires that the implementation 
use visible writes.
% , while eager write/read conflict detection can use either visible reads or visible writes.
% \anote{Not sure about write/read}

% If visible writes are used than read/write conflicts are detected sooner than if invisible writes are used.
Visible writes allow write/read and write/write conflicts to be detected eagerly.
Read/write conflicts are detected eagerly when the write operation takes place, observing that the location
had been previously read by another live transaction.
Similarly, write/write conflicts are detected eagerly when the latter write takes place, observing that
the location  had been previously written by a separate live transaction.
% because when a write occurs (or the writing
%  transaction tries to commit) the writing transaction checks to see if there are
%  any active readers in the list for this memory location, and if there are, then
%  a read/write conflict has occurred and is dealt with according to the implementation and contention manager.

Visible reads allow read/write conflicts to be detected eagerly.
When the write occurs it detects that the location has been read allowing
the conflict to be dealt with eagerly.

% The visibility of writes and reads effect write/read conflicts.
% If a write is visible then from when a transaction acquires the write lock until
%  it commits (or aborts), if a separate transaction performs a read at this location
%  then a write/read conflict is detected and the conflict is dealt with.
% With invisible writes, write/read conflicts can still be detected eagerly,
%  but require visible reads and are not detected until the writing transaction commits.
% When the writing transaction commits it will check if there are any 
% readers for the memory location, and if there are then a write/read conflict has occurred and is dealt with.
% 
% When a write occurs the transaction checks to see if there is another 
% transaction that owns the lock on this memory location, and if there it
%  means a write/write conflict has occurred, and the conflict is dealt with according to the implementation.

\paragraph{Lazy}
Read/write, write/read, and write/write conflicts can be detected lazily,
using invisible reads and writes.
%  cause the transaction to see an inconsistent view of the memory (depending on the consistency condition).
% They all use invisible reads and writes.

The lazy detection of a write/read or read/write conflict is done by the transaction performing the read.
In the case of a write/read conflict, if the transaction performing the write has already committed then the
conflict is detected at the time of the read, otherwise
the conflict is detected later, either
during the reading transaction's next read operation or during its committal.
Read/write conflicts are also detected during the first transactional read
or commit to follow the committal of the writing transaction.
In order to detect either of such conflicts, the reading transaction
 must \emph{validate} its read set any time a transactional read is performed as well as during committal, 
ensuring that the set of reads done by this transaction have a serialization point where
they are all valid according to the consistency criterion.
% Since the transaction doing the write has no idea the read has occurred 
% it is usually unaffected by the read.

Lazy write/write conflict detection occurs at the commit time of the
later writing transaction.
% The transaction that commits first has no idea there is a conflict so 
% it is usually unaffected.
When the later transaction commits it must make sure that the consistency criterion is not violated
by the conflict.
Interestingly, many TM implementations choose their serialization point to be at the time of their 
commit operation, meaning that if the transaction did not perform a transactional read to the location
of the write/write conflict (in addition to the read) then the conflict will clearly not violate consistency.

% In order to make sure its operations are viewed a atomic when a writing transaction
%  is committing in most implementation it will grab some sort of lock or set a flag
%  for the memory locations it is going to write preventing other concurrently committing
%  transactions from writing to these locations.
% When a concurrent transaction tries to commit, but notices that some other
%  transaction is also committing to the same memory, a write/write conflict 
% also occurs and must be handled by the TM implementation.


\subsubsection{Dealing with conflicts}
Once a conflict is detected the STM system must then choose a way to deal with it.
Contention management was originally implemented in DSTM \cite{HLMS03} as an out-of-bound mechanism
that a transaction would call when it detected a conflict with another transaction, 
asking whether it should back off, abort, or tell the conflicting transaction to abort.
% DSTM was proposed with two possible contention management policies \emph{aggressive} and
%  \emph{polite}.  In the aggressive policy when a transaction detects a conflict, it immediately forcefully aborts the conflicting transaction.
% In the polite policy, when a transaction detects a conflict, it will back off and wait
%  a certain amount of time.
% When the transaction starts back up if the conflict still exists the transaction will back 
% off again for some exponential and possibly randomized amount of time, this cycle will continue 
% until some given time threshold is reached, at which time the conflicting transaction will be forcefully aborted.
% The hope of the back off is that the extra time will allow the conflicting transaction to 
% commit or abort possibly removing the conflict and avoiding aborts all together.
Since DSTM was introduced various contention managers have been proposed, each with varying 
levels of complexity, admitting increased overhead in the hopes of increasing liveness and producing better overall performance.
Some of these include \emph{passive} (or \emph{suicide}), in which a transaction aborts itself
 whenever it detects a conflict, \emph{timestamp} in which an older transaction aborts younger
 transactions and a younger transaction waits for older transactions to finish, \emph{karma} which
 uses a heuristic to determine the amount of work a transaction has done, then aborts the one that
 has done the least amount of work, and \emph{polka} which extends karma by adding a randomized exponential back-off mechanism.

\paragraph{Difficulties}
Mostly these contention managers have been proposed and designed by making certain assumptions about
 what applications transactional memory will be used for, then validating (or disproving) their assumptions
by examining the contention manager's performance on a limited set of workloads.
Part of the difficulty is that a contention management strategy that may work well for one STM 
implementation may not work at all for another, this is based on how the STM implements things such as
 visibility of reads, and eagerness of acquire for writes \cite{DGK09}.
Given this, certain TM implementations such as LSA-STM have been tested using a wide array of 
different contention managers \cite{RFF07} but there is no definite answer as 
to what type of contention manager works best for which TM properties.

A workload can largely effect how well a contention manager performs, for example passive contention
 management is know to perform well on workloads with a regular access pattern \cite{1504199}, while
 polka \cite{1073861} works well on small scale benchmarks \cite{DGK09}.
The obvious problem with this is that there is no "best" contention manager that performs well in 
all reasonable situations, in \cite{guerraoui05polymorphic/LPD} they come to this conclusion by 
running a set of the top performing contention managers on a range of benchmarks designed to simulate real world applications.

\paragraph{Liveness}
Unfortunately many contention managers do not actually prove any guarantee of progress, they often
 only suggest why they should work well, there are possibly workloads that can be generated that 
cause extremely poor performance and admit the live-lock or starvation of transactions.
The contention manager \emph{greedy} \cite{GHP05} is an exception to this,
it is proven to prevent live-lock and starvation, yet in oder to ensure these properties it
 introduces a high amount of contention on some shared meta data, resulting in poor performance in
 workloads with a large amount of short transactions \cite{DGK09}.
The liveness and progress of transactional memory is discussed in more detail in chapter
\ref{chap:UC}.

% Similar to being livelock free, but not quite as powerful, greedy ensures the \emph{pending commit} 
% property, which ensures that at any time, some running transaction will run uninterrupted until it commits.
% Greedy works by assigning a timestamp to each transaction when it starts, then when a transaction 
% $A$ discovers a conflict with a transaction $B$ it will abort $B$ only if $B$ has a later timestamp 
% or if $B$ is waiting on another transaction, otherwise transaction $A$ will start waiting.
% Note that the timestamp is kept even after a transaction is aborted and restarted.




















\section{Simplicity}
Given that there are so many different interesting properties to consider
when thinking about transactions, it is easy to loose sight of the what
we are really looking for.
It is important to remember that he primary goal of transactional memory is to make concurrent programming
easier and more accessible, with performance following closely as a secondary goal.
In reality unfortunately, neither of these goals have yet been realized.
As we will see in each chapter of this thesis there are complex aspects
of the STM abstraction that involve how a programmer interacts with the
STM system and the system as a whole in a modern concurrent environment.
While the basic semantics of a transaction are widely agreed on
(i.e. transaction atomicity with respect to other transactions),
there are many other details to consider
some of which are actively debated and remain as open research questions.
Standardizing these semantics and answering open questions on them is an important
step in ensuring that the primary goal of making concurrent programming easier
is realized.
If the semantics are either too hard to understand, or a programmer has to be aware of
too many details specific to an STM system before being able to use transactions in
his program then the sight of the original goal has been lost.

Interestingly, while no agreement exists on the full semantics of transactional memory,
there has still been much research that focuses on performance first.
Likely the reason for this is because even though STM in its current form has been shown
to be efficient for certain workloads \cite{DFGG11}, many people argue that
its performance is not good enough to be an attractive alternative to locks, even considering all the
difficulties that surround using locks.
% This thesis takes the approach of finding the correct semantics for transactional
% memory before trying to improve performance as why try to improve the performance
% for something that is not fully defined and might change?
Instead of taking this approach of directly tackling the problem of performance,
% Given the difficulties that currently exist for finding the correct semantics for transactional memory
the goal of this thesis is to take a step towards finding and defining fixed and easy to understand semantics
for transactions while finding efficient protocols satisfying these semantics.
After defining such semantics, a following important step is to then see what sort of performance they might
offer and see how easily programmers can use them, taking this information to improve the semantics
possibly in an iterative fashion.
This leads us to the following concept that is the focus of the thesis:

\begin{definition}\label{def:stm-def}
STM is an abstraction designed to simplify concurrent programming that exists as a component of a larger system,
but the semantics of the STM abstraction and how it interacts with the rest of the system must be clear and easy to understand and use,
otherwise simplicity is lost.
\end{definition}

\subsection{Defining a transaction}
% Even though transactional memory is designed as an abstraction focused on making
% concurrent programming easier, 
Before deciding the semantics of an easy to use STM a high level
definition for a transaction must be decided.
% As will be shown in each chapter there are complex aspects
% of the STM abstraction that pose significant open research questions on how the programmer interacts with the
% STM system in a modern concurrent environment.
Due to the fact that transactional memory is a high level abstraction designed for ease of use
that exists in a concurrent system
a transaction should be defined in a way that minimally impacts the complexity
of this system.
% this
% thesis takes an approach to answering these questions in a way attempting to minimally impact complexity
% of the system.
Following this approach the following high level definition for a transaction as follows:

\begin{definition}\label{def:trans-def}
A transaction is any block of
code defined by the programmer to be executed by a given process.
This transaction is executed atomically exactly once
taking in consideration all parts of the system.
\end{definition}

This definition is broken down into two key parts.
The first, more obvious key part is (1) a transaction is defined by the programmer
and is executed atomically.
The second, but maybe not so obvious key part is (2) a transaction exists
as part of a complete system containing many components other then this transaction and a relation between them must be
defined.
This second part is important because when a programmer is writing a concurrent program there are many things
other then the current transaction he is writing to consider.
This could include things such as the actions of other processes, the interactions
of objects and memory in the system with this transaction, among other things, many of
which are explored in this thesis.
Each chapter in this thesis will then take this definition of a transaction,
and by helping to formalizing its parts move towards the realization of the
goal in Definition \ref{def:stm-def}.


% As such the goal is to help define the semantics of software transactional memory
% that a programmer can use without being an expert in the area.
The grand goal is that someday a programmer can write an efficient concurrent program
with nearly as much ease as he would write a sequential one.
While this goal is far from fully achieved here,
this thesis makes important steps in this direction, while suggesting ways to move forward further.

% In reality we can not immediately realize or even know if this goal is possible yet for there are far too many questions left open when dealing
% with the semantics of transactional memory, to many even to introduce in this thesis or let alone solve.
% Instead, this thesis will look at what we
% believe are the main areas of transactional memory research that take the
% ease-of-use as a primary concern.
% In this way, each chapter will separately introduce a research area before looking closely at a specific open
% problem from that area and suggesting an STM protocol as a solution to the problem.
% Finally each chapter will mention some of the well know open questions from each area.







\subsection{Thesis outline}

Each chapter in this thesis consider a different general area of research around
the concept of the ease (or difficulty) of concurrent programming while using transactional memory, first introducing
the area to the reader, following this with a discussion of a specific problem
and possible solution from the area, each helping to move towards a solution to Definition \ref{def:stm-def}.


Traditionally research has taken the view that for a protocol to be considered a valid STM
implementation then it should ensure transactions
are atomic with respect to each other and all transactions (aborted transaction included)
execute in a consistent state of memory.
Once this is satisfied the research then focuses on improving the implementing protocol
by increasing its performance or having it satisfy desirable properties
(interestingly, this properties are usually related to improving performance).
Following this model, the first chapter looks at the specific properties of \emph{invisible reads}
(a property important for the speed and scalability of an STM) and
\emph{permissiveness} (a property preventing a protocol from aborting transactions unnecessarily)
showing that they are not compatible with the correctness condition
of \emph{opacity} before introducing a protocol that does satisfy these properties using
the correctness condition of \emph{virtual world consistency}.
% See the chapter for the definition of these properties.

When using this traditional view of transactional memory,
issues that are not solved by ensuring a consistency criterion such as opacity are left up to the programmer.
Some of these issues include things like how to deal with aborted transactions, how to deal
with memory accessed inside and outside of transactions, how transactions are nested,
how to deal with I/O, among others.
The programmer then has to understand these issues and must then choose an
appropriate STM protocol based on his needs.
The second and the third chapters look at research that takes the approach
that requiring the programmer to make these decisions
is not appropriate for an easy to use concurrent programming abstraction.
The second chapter suggests looking at ways to simplify the traditional STM
semantics while the third chapter suggests expanding the traditional semantics to consider
issues that are likely to come up when using STM in a realistic system
(things that are ignored by consistency criterion such as opacity)
and provide straightforward solutions to them.


Specifically, the second chapter looks at research that takes the view that for transactional memory to
be easy to use the semantics defined in the first chapter should be simplified, meaning that,
in a sense, the abstraction level should be raised.
In detail it looks at the problem of aborted transactions and suggests that
the programmer should not have to be aware of aborts at all, following this suggestion it introduces a protocol
that ensures every transaction issued by a process commits no matter the concurrency pattern
of other threads in the system.

The area of research looked at in the third chapter suggests expanding the basic semantics of transactions.
Taking just the traditional definition of transactions from the first chapter only leaves a very limited view of how
transactions fit into the big picture of concurrent computing.
It only considers the interaction between transactions themselves,
%  and ensuring the read and write
% operations within them at atomic with respect to the other transactions.
leaving the interaction between
transactions and other entities in the system undefined.
This is not optimal considering ease-of-use as if a programmer uses
some of these mechanisms he would encounter undefined results or will have
to be familiar with how different STM protocols specifically interact with 
each of these mechanisms.
% The specific problem that this chapter looks at is the interaction between shared memory
% accesses inside and outside of transactions.
This chapter specifically looks at shared memory accesses, attempting to answer the question, ``how should the system act when shared memory
is accessed inside and outside of a transaction?''
To answer this we suggest and define a term called \emph{terminating strong isolation} which ensures
that a transaction's atomicity will not be violated by reads and writes performed
outside of the transaction by other processes without holding back the progress of
these reads and writes.
A protocol protocol ensuring this property is presented.

% The subject of the fourth chapter is probably the least interesting theoretically, but
% shows no less ambition then the previous chapters.
% The fourth chapter looks at how to merge the research
% from the previous chapter.
% After all it is nice to give different suggestions for how the semantics
% of transactions should be modified, but it is less meaningful if they are not compatible with
% each other and we instead have to pick and choose.
% In STM research someone might introduce a protocol that does something really neat, but
% if this protocol is only valid for a limited amount of situations then it probably
% is not helping solve the primary goal.
% This chapter describes a protocol that considers some of the properties suggested
% in the first chapter, while hiding the notion of abort from the programmer,
% and ensuring terminating strong isolation. 
% \anote{Hopefully!}

The fourth chapter looks into the idea of providing efficient abstractions
as libraries for programmers to reuse from within their transactions.
Not only does this mean the programmer does not need to design such libraries himself, but
it allows an expert programmer who knows well the synchronization pattern of STM
to write high performance implementations designed specifically for transactions.
It looks into designing efficient data structures implementing the map abstraction.


The final section concludes the thesis by providing a closing discussion on
the contributions presented in the chapters
as well as possible future extensions of the concepts and protocol described in.






% By solving small problems in each one of these areas hopefully this thesis will
% help move forward the ease of use of transactional memory and by mentioning
% some of the open problems in each of these areas will hopefully promote
% future strides towards ease of use.




% 
% \section{Transactional Memory}
% \emph{Transactional Memory} was first introduced in 1993 \cite{165164} as a promising alternative to locks for concurrent programming.
% Since then it has been studied extensively and implemented in many different ways.
% One of the main reasons for its success as a research topic is that it abstracts away much of the difficulties that occur for programmers writing concurrent programs when using locks, while still promising the performance of fine grained locks.
% Even though it has been a popular research topic, it has yet to be widely implemented in practical use.
% \textcolor{Red}{I think?}
% The basic concept behind transactional memory may be clear, but when it comes to actually creating and using an implementation, solving the details becomes very difficult.
% Such details include but are not limited to the following:
% How should the transactions be exposed to and interact with the programmer?
% What correctness conditions should transactions follow?
% How can transactions be implemented efficiently?  Is it even possible to create a Transactional Memory that is efficient across all workloads?
% If not then what designs will be efficient for which workloads, or can the concept of the basic transaction be extened in order to improve performance?
% Much research has been done on all these topics and many different concepts of Transactional Memory have been considered, this survey gives an overview of some of the research that has been done on Transactional Memory, specifically looking at \emph{Software Transactional Memory}.
% 
% \subsection{What is transactional memory?}
% Transactions have been originally used in database systems in order to make sure concurrent operations follow desirable properties.  Namely the ACID properties: \emph{atomicity}, \emph{consistency}, \emph{isolation}, and \emph{durability}.  Transactional memory is similar to this, except instead of having transactions that \emph{atomicall}y modify the state of the database, transactions are blocks of executable code running concurrently.
% In both database transactions and transactional memory much of the difficultly of accessing shared objects is abstracted away, making concurrent programming a much more manageable task.
% 
% In transactional memory a transaction is a block of code that appears to execute atomically within a multi-threaded application that operates on memory shared with other threads and transactions.
% To the programmer this might be similar to the idea of having a single lock that is shared throughout the program, whenever the programmer wants a section of code to operate atomically or without interference from other threads he can just encapsulate the block within this single lock, this concept is called \emph{single lock atomicity},.
% So why not just program using a single lock?
% The problem with just using course grained locks like this, is that it inhibits concurrency resulting in poor performance.
% On the other hand fine grained locks can have good performance, but are difficult to program well, and can suffer from problems such as \emph{deadlock}.
% The goal of transactional memory is to be simple for the programmer to understand similar to coarse grained locks, while having good performance similar to fine grained locks.
% The concept behind the implementation of transactional memory is that a transaction will either commit, meaning that it executed successfully and its changes to shared memory become visible to other transactions, or abort, meaning that it conflicted with a concurrent transaction and that none of its changes to shared memory will be visible, and it must retry by re-executing from the start of the block of code that makes up the transaction.
% Two transactions conflict when they are run concurrently and access the same memory location, with at least one of the accesses being a write.
% Aborting a transaction causes overhead, the work it has done so far must be completely redone, so most implementations try to abort transactions as little as possible.
% But just because two transaction conflict does not mean that one must be aborted.
% For example assume you have two transactions $A$ and $B$, a shared memory location $X$, and the ordered history of events as follows:
% (Note that in this survey a single transaction's execution will be interpreted as a series of read and write operations ending in a commit (or abort))
% $$ start_{B},start_{A}, read_{A_{X}}, write_{B_{X}}, commit_{B}, commit_{A}$$
% Now as long as the transactions are ordered first $A$ then $B$ neither one must abort.
% As an example where two transactions must abort assume you have two transactions $A$ and $B$, two shared memory locations $X$ and $Y$, and the ordered history of events as follows:
% $$start_{B}, start_{A}, read_{A_{X}}, write_{B_{X}}, write_{B_{Y}}, commit_{B}, read_{A_{Y}}, commit_{A}$$
% Now the neither the order first $A$ then $B$ or first $B$ then $A$ is possible.  $A$ reads $X$ before $B$ writes $X$, so $A$ must occur before $B$, and $B$ writes $Y$ before $A$ reads $Y$, so $B$ must occur before $A$, creating a contradiction.  One of the transactions must be aborted.
% 
% Aborting transactions means work has been wasted, but keeping track of all the conflicts between the transactions is not easy and deciding when and if a transaction should be aborted is no simple task, in some cases it can even be more efficient to abort transactions more eagerly than to keep track of all conflicts.
% There is also liveness to consider, should a transaction be allowed to be repeatedly aborted forever by other transactions?
% And how should efficiency be measured?  For example consider the workload that consists of a set of long running transactions that conflict with a set of short running transactions.
% Some implementation might allow the short transactions to commit, aborting the long transactions each time, while another system might allow the long transactions to commit, aborting the short transactions, while another might be somewhere in the middle.
% Should efficiency be measured by the number of transactions committed per unit time, or should it be measured by the total number of aborts, or some other measurement?
% In addition to this there are different consistency conditions to consider, in some conditions a transaction that is allowed to commit would have to abort in other conditions.
% Many of the solutions to these questions differ depending on application and workload, and there is often no obvious solution.
% 
% \paragraph{STM/HTM}
% There are two main approaches for designing a Transactional Memory, \emph{Hardware Transactional Memory} and \emph{Software Transactional Memory}.
% Each has its strengths and weaknesses.
% Hardware Transactional Memory is implemented in the underlying architecture and can be very efficient, but transactions are bounded in size and restricted to the capabilites of the hardware.
% Software Transactional memory can be implemented on existing hardware and can have transactions of arbitrary size, but often do not have as good performance as Hardware Transactional Memory.
% There has also been research done for creating hybrid models combining both hardware and software.
% This survey will focus on Software Transactional Memory.
% Articles giving an overview of both STM and HTM can be found in \cite{10.1109/MM.2007.63} and \cite{1364800}.
% 
% \section{Characteristics of a STM (for a Programmer)}
% Deciding how a programmer should interact with an implementation of Software Transactional Memory has been a subject of interest and difficulty.
% This includes how the programmer creates the transactions themselves as well as how he accesses the shared memory.
% 
% \subsection{Static vs Dynamic Transactions}
% A \emph{static} transaction has its memory accesses predefined, before the code is run.
% Knowing what memory access the transaction is going to perform beforehand can help the implementation of the STM in terms of simplicity and performance, but is severely limiting to the programmer.
% With \emph{if} statements, and loops the exact execution path of a program is usually unknown so it is not practical to have static transactions.
% The first STM implementation was static \cite{224987}, and certain other static implementations have been designed in the interest of performance gains \textcolor{Red}{need a citation}.
% Most STM implementations use \emph{dynamic} transactions, allowing the memory access to be undefined until runtime.
% 
% \subsection{Word Based}
% With \emph{word based} Software Transactional Memory shared memory locations are accessed as specific words of memory.  Many popular STMs are word based, such as TinySTM \cite{10.1109/TPDS.2010.49}, Swiss-STM \cite{1542494}, Elastic-STM \cite{LPD-REPORT-2009-002}, AVSTM \cite{LPD-CONF-2008-031}, and TL2 \cite{Dice06transactionallocking}.
% An advantage of word based STMs is that all transactional memory access are easily abstracted into reads and writes to the words of memory which is useful for clearly designing and analyzing STM algorithms.
% Though is might no be clear to the programmer to access memory as words, especially in object oriented languages.
% The size of the shared memory access is of course important when considering performance, and in order to minimize cache misses the size of a cache-line has been proposed \cite{1123001}, but in \cite{1542494} they believe a granularity size of four words gives optimal performance.
% 
% \subsection{Object Based}
% Object based Software Transactional Memory is where shared memory locations are accessed by the programmer as objects.  This is more natural for the programmer to understand, especially in object oriented languages, and is also shown to be easily optimized by compilers \cite{1133985}.
% The construction of the STM is often different than word based implementations due to the fact that objects are accessed by pointers creating an additional level of indirection.  There are also many object based STM implementations with many interesting properties including RSTM \cite{Marathe06loweringthe}, LSA-STM \cite{10.1109/TPDS.2010.49}, DSTM \cite{872048},  \cite{Ennals05efficientsoftware}, SXM \cite{guerraoui05polymorphic/LPD}, and JVSTM \cite{1228566}.
% 

% Even is a programmer is able to correctly write a program using transactions, it does not mean that it is a good program.
% As described in this survey there are many different ways to implement transactional memory, and they can each deal with transactions very differently resulting in varying performance for varying workloads.
% For example certain STM implementations might perform better or worse depending on the length of a transaction, while others might perform better if a programmer puts write acceses to memory early in a transaction, while still others might perform best if some of the additional STM language constructs specific to that implementation are used.
% Because of this variation, there are currently no \emph{"best practicies"} for programming using transactional memory and if a programmer wants to create the best program he has to find an implementation of Transactional Memory that is well suited for his application, and has to organize his code such that it is most efficient for the implementation he chose.
% This adds an additional learning curve for programmers, and is partially contradictory to the original idea of transactional memory, which is to abstract away the difficulties of concurrent programming.
% There are certain approaches to help take some of the burden off programmers to write efficient code such as using compilers to improve efficiency \cite{1133985}, or even to completely remove the concept of transactions from the programmer, and have them generated automatically. \textcolor{Red}{need citation, check Distributed computing column 29}
% 






% \subsubsection{Opacity}
% \emph{Opacity} \cite{LPD-CONF-2007-017} was the first formally defined consistency criterion for transactional memory, it is also the most widely used and understood.
% It can be simply stated as linearizability for all transactions, including aborted ones.  So all transactions must access a state of memory that has been produced by the previous committed transactions, and must be orderd based on real time execution.
% After a transaction reads an inconsistent state of memory it must not be allowed to execute any following statements.
% This prevents the bad behaviors (described previously) from happening due to reading an inconsistent state of memory.
% Consider the prefix of an aborted transaction upto the operation that caused the abort.
% For all aborted transactions this prefix must be ordered along with the committed transactions for a valid sequential execution.
% One important thing to notice is that both opacity and linearizability guarentee that a transaction looks to have executed atomically at any one point in its real time execution, not necessarily at its time of completion.
% So any concurrent transactions can be ordered in any way and depends on implementation, this flexibility gives the possibility to commit more transactions.
% 
% \subsubsection{Virtual World Consistency}
% Imbs and Raynal recognized that for certain workloads opacity might be too strong of a consistency condition, so they defined \emph{Virtual World Consistency} which is strictly weaker than opacity, but still ensures transactions only see consistent states of memory, preventing the undesirable effects of reading inconsistent states.
% In opacity aborted transactions can effect whether another transaction can commit or not due to the fact that aborted transactions must be serialized along with committed transactions.
% They give the following example in their paper:
% \textcolor{Red}{use figure?}
% In virtual world consistency aborted transactions must see a consistent state of the memory, meaning that if you take the a prefix of the aborted transaction, the events up to, but not including the event that caused it to abort, there must exist a serialization of it with previously committed transactions, but other concurrent and later transactions need not be considered.
% This serialization of other transacions up to the transaction in question needs not necessarily to be the the same serialization that some other concurrent transaction sees (whether or not the concurrent transaction commits or not).
% On the other hand all commited transactions must see the same serilization.
% For example the view of an aborted transaction might not contain a transaction that was serialized before (in the committed history) some other transaction that the aborted transaction does see.
% Imbs and Raynal also give an STM algorithm that uses sequence numbers to keep track of writes to variables and satisfies virtual world consistency.  This algorithm accepts certain histories that are virtual world consistent, but not opaque.  They give a formal proof that the algorithm satisfies virtual world consistency.
% They prove that virtual world consistency will accept more histories than opacity, but how and if this is helpful in parctice is left unexaimed.
% 
% \subsubsection{Snapshot Isolation}
% \textcolor{Red}{Need to write this section}
% 
% \subsubsection{Consistency Criterion Limits}
% After Gerraoui and Kapa\l{}a define opacity \cite{LPD-CONF-2007-017} they prove an upper bound for a certain type of TM implementations that ensure this consistency condition.
% Namely single version TMs with invisible reads that do not abort non-conflicting transactions and ensure opacity require in the worst case $\Omega{}(k)$ steps for an operation to terminate, where $k$ is the total number of objects shared by transactions.
% 
% The choice of consistency criterion obviously makes a large impact on a STMs implementation and performance, yet much of this relation is widely unknown.
% The previous paragraph gives one result showing a cost of choosing opacity for a TM implemented in a certain way.
% Opacity is the most widely studied and implemented consistency criterion and some research has been done on different aspects of how it effects implemntations, but there is still much to be done.
% Part of the difficulty is that consistency criterion is just one of many different design choices one can make for a TM that all impact eachother, and there is no universially accepted definate choice for any of these.
% For example any combination of choices for read visibility, write visibilty, blocking, livness, consistency, nesting, privatiztion, is just as valid as some other combination of these choices (these terms are discussed later in this survey).
% Many of these different combinations have been shown to work well on certain workloads or benchmarks, but very little theoretical results have been proven.
% Also few specific TM implementations formally prove their consistency criterion or show how the choice of criterion effects their implementation choices and performance.
% It is hopeful that as more theory is proven the choice of how to implement a TM will become more clear.
% As this survey introduces the different concepts behind STMs it will discuss some of the theory that has been proven for them.
% 
% \subsubsection{Other Consistency Criterion}
% There are many other consistency criterion that have been proposed and implemented.
% For instance in order to increase the commit rate of transactions, removing the real time requirement of ordering transactions from opacity has been considered, defined in \cite{LPD-ARTICLE-2009-004} as \emph{real-time relaxation}.
% In \cite{Alvisi_lock-freeserializable} Alvisi defines a lock-free STM that follows this criterion.
% Another STM that implements real-time relaxation and is also decentralized is defined in \cite{LPD-ARTICLE-2009-004}.
% In the same paper they examine the acceptance of different transaction memory implementations based on different criterion they implement including consistency.
% Again in order to increase performance certain STMs can allow transactions that will eventually be aborted to access inconsistent states of memory following the definition of serializability or linearizability from database transactions.
% This usually leaves the programmer to deal with the problems that come with accessing inconsistent states of memory.
% Even though opacity and virtual world consistency have both been formally defined, and opacity has been partially exaimned, other consistency criterion have been studided even less, and for some TMs implementations their consistency criterion has not even been formally defined.
% 
% Certain other mechanisms available to programmers have been proposed such as \emph{early release}, proposed in \cite{872048} which allows programmers to tell the system to treat some memory location it has read as if the read did not actually happen in order to increase the chance of committing the transaction.
% Another mechanism proposed in \cite{LPD-REPORT-2009-002} is \emph{elastic transactions} which allow the programmer to mark transactions that can be split into multiple transactions at runtime also in order to increase the commit rate.
% Both these and possibly other mechanism effect the consistency of an implementation, but the changes they cause to consistency, performance, and bounds are widely unstudied, and their effects can often be unclear to a programmer leading to possible errors.
% 
% \subsection{Privatization}
% Another question on correctness is how should shared memory be dealt with outside of transactions, this is called \emph{privitization}.
% Many TM implementations do not address the issue of privatization, yet it is important, as a piece of code that is correct in one implementation may be wrong in another given by how they deal with privatization.  For example consider the following transactions $A$ and $B$ and a shared list object $list_x$.
% 
% \paragraph{Transaction A}
% % \begin{algorithmic}[1]
% % \STATE $BEGIN\_TRANSACTION_A$
% % \STATE $list \gets list_x.head$
% % \STATE $list_x.head \gets null$
% % \STATE $END\_TRANSACTION_A$
% % \FORALL{\emph{elements in list}}
% % \STATE \emph{Perform some operation on the list elements}
% % \ENDFOR
% % \end{algorithmic}
% TODO
% 
% \paragraph{Transaction B}
% % \begin{algorithmic}[1]
% % \STATE $BEGIN\_TRANSACTION_B$
% % \STATE $list \gets list_x.head$
% % \FORALL{\emph{elements in list}}
% % \STATE \emph{Perform some operation on the list elements}
% % \ENDFOR
% % \STATE $END\_TRANSACTION_B$
% % \end{algorithmic}
% TODO
% 
% This example is similar to the one in \cite{}. \textcolor{Red}{in the guys phd thesis on page 156}
% Transaction $A$ reads the head of a list, and then sets the shared pointer to $null$ in the hopes that no other transaction will be able to access the list.
% Once the transaction commits, the code goes through the list performing some operations on the elements non-transactionally.
% Transaction $B$ reads the head of the list, then goes through the list performing operations on the list while in the transaction.
% Now assume the following order of execution happens.
% Transaction $B$ starts executing and gets to line $3$, now transaction $A$ starts executing and commits successfully.
% After transaction $A$ commits, the non-transactional code following $A$ continues to perform some operations on the list concurrently with transaction $B$, which is performing operations on the same list, resulting in some undesireable behavior.
% Notice that transactions $A$ and $B$ are concurrent, so in the described execution as long as they are serialized as $A$ first, then $B$, they can both be committed and satisfy opacity.
% 
% In order to avoid problems such as this there are different models to deal with privatization, they each have trade offs on efficiency and programmer involvement.
% 
% \subsubsection{Strong Isolation}
% A transactional memory that provides \emph{strong isolation} guarantees that transactions are isolated from other transactions operations on shared memory as well as from non-transactional loads and stores.
% In this model the example above would not be allowed to happen.  This could be done in several ways, one way would to not allow the code to compile at all.  In \emph{STM Haskell} \cite{sjbc000} variables are declared as either transactional or non-transactional, and only transactional variables are accessible inside of transactions, and only non-transactional variables are accessible outside of transactions, preventing code like the example above.
% \textcolor{Red}{does this weaken the programming in any way?}
% Another solution would be for the transactional memory implementation to execute the code in a way so that the non-transactional accesses do not interfere with the transactional accesses.
% This is called \emph{transparent privatization}, where the STM itself guarantees all transactions privatize data correctly.
% In \cite{spear:privitization:podc:2007} they introduce a way of implementing transparent privatization called \emph{validation fences} where after a transaction commits, it waits until all concurrent transactions to finish executing (committing or aborting) before executing any non-transactional code that occurs after the transaction.  Of course this can limit performance and scalability, especially in workloads that have long transactions, and in order to write efficient code the programmer may have to know that privitization is implemented in this way.
% In order to implement a more efficient and scalable privitization, SkySTM \cite{lev:anatomy:transact:2009} uses \emph{conflict-based} privatization which allows transactions to only wait on conflicting transactions to finish.
% 
% \subsubsection{Semi-visible Privitization}
% \textcolor{Red}{mention semivisible privitization from the guys phd thesis?}
% 
% \subsubsection{Weak Isolation}
% A transactional memory that satisfies \emph{weak isolation} guarantees only that transactions are isolated from each other.  In this model the example above would be allowed to happen.
% Most transactional memory implementations that do not mention privatization probably satisfy weak isolation.
% Usually these implementations assume a model similar to single lock atomicity, where if there is concurrent access to the same memory location within the lock as there is outside a lock, then this is considered a bug, likewise in a TM if there is a concurrent access to shared memory inside a transaction as there is outside a transaction, then this is programmer error.
% Certain implementations deal with this by allowing the programmer indicate when he wants to privatize data, this is called \emph{explicit privatization}.
% So that when a programmer privitizes the data he can be sure that it is no longer accessable by transactions.
% Again this is a trade off, weak isolation and explicit privatization are aimed at improving performance, but has the side effect of making code more difficult for the programmer to write.
% 
% 
% \subsection{Error Handling}
% An overview of error handling in transactional memory is given in \cite{1360456}, may of the concepts introduced there are repeated here.
% What should happen when an exception occurs midway through a transaction?
% For example say within a transaction there is some code that opens a file for reading, but when it tries to open it, the file has been previously deleted and an exception is thrown.
% Or say a transaction for a bank application transfers money from one account to another, but in some case when it tries to do this an exception is thrown because there is not enough money in the first account.
% 
% one way of dealing with this could be, abort the transaction, and restart it, similar to if it was aborted due to a shared memory conflict.
% With the bank application this could possibly be acceptable, because the transaction will be executed successfully once enough money is deposited in the first account.
% For the file transaction this may or may not be acceptable, for example the file might have been permanently deleted, and the transaction will be aborted and re-executed indefinitely.
% 
% Another solution might be to partially commit the transaction up to the exception, then propagate the exception.
% This can be viewed as similar to what happens in sequential code, when an exception is thrown in a sequential execution, the code up to what caused the exception was executed sucessfully.
% Unlike in sequential code doing this in transactions violates the expected atomic all or nothing behavior which can cause problems if the programmer does not deal with this correctly.
% For example say the money transfer transaction first increments the balance of the destination account and then decrements the source account, and if there is not enought money in the source account then some exception specifc to this is thrown.
% This may seem rediculous, but the programmer writes the code that handles this exception by consequently removing the amount added to the destination.
% But after the transaction is partially committed, and before the exception is handled, the system is in some sort of inconsistent state, and any number of bad things can happen, for example the money desposited in the destination account might be withdrawn by some other transaction. \textcolor{Red}{maybe can think of a better example?}
% 
% A third solution might be to abort the transaction and propagate the exception, but this requires the programmer to make sure he handles the exception correctly knowing that the code that caused the exception and the code prior to it in the transaction appears as if it was never executed to the rest of the system.
% 
% A fourth solution might be to require exceptions to be dealt with from within the transaction, similar to the following try, catch syntax in Java.
% % \begin{algorithmic}[1]
% % \STATE $BEGIN\_TRANSACTION$
% % \STATE $try \{$
% % \STATE $...$ transaction code
% % \STATE $\}$ $catch($Exception ex$) \{$
% % \STATE $...$ error handling
% % \STATE $\}$
% % \STATE $END\_TRANSACTION$
% % \end{algorithmic}
% 
% TODO!!
% 
% Certain STMs implement their own mechanisms not specifically designed for handling exceptions, but that can be used for exception handling.
% For example STM Haskell \cite{sjbc000} has a mechanism that allows a transaction to follow a different execution path after it is aborted and retried.
% This mechanism even allows the programmer to abort the transaction for anywhere within the transaction's code.
% 
% Due to the notion that transactions observing inconsistent states of shared memory can cause problems as described in the section of this survey on consistency criterion, most implementations ensure the opacity consistency criterion, where all live transactions observe a consistent view of shared memory.
% In the interest of efficiency weaker consistency conditions that allow inconsistent views of memory have been considered, but rarely examined deeply because of possible problems.
% Well done error handling could likely deal with these problems and lead to the possibility of these and other new consistency conditions be more widely considered.
% 
% It is interesting to study how exception handling and its implementations can effect and bound correctness, liveness, and performance theoretically and in practice.
% Currently there is no obvious answer to handling exception in transactional memory and what works best might vary depending on the application and implementation.
% But if implemented correctly error handling in TMs could actually benefit code execution over sequential code.
% In transactional memory, a sequence of code that caused an exception could be automatically rolled back and then executed in a way that would prevent the exception.
% While in sequential code it might be difficult to make sure the sequence of code up to the exception is rolled back.
% 
% \subsection{I/O}
% I/O is also a subject of difficulty in transactional memory because it is not always obvious how to abort and rerun an I/O operation.
% Take for example a transaction that writes some data to the screen, and then is aborted, the characters written could then be deleted from the screen, but this would be strange for the user.
% Output could be buffered until a transaction commits and then displayed, but this could cause performance issues.
% Input is also difficult because it often requires real time performance, and there are questions like should the input be repeated on abort, or should the previous values be reused?
% The answers might be application specific.
% 
% A simple solution might be to disable I/O operations from being executed within transactions, such as in STM Haskell \cite{sjbc000}, but this might not always be possible, and might create difficulties in programming which may vary in conjunction with the chosen privitization technique.
% \textcolor{Red}{what effect does this exactly have on restricting power of programming?}
% 
% Another solution implemented in \cite{1504199}, called \emph{inevitability}, allows a transaction with I/O operations to be marked as inevitable so that it is never aborted, whenever it conflicts with a transaction the other transaction will be aborted.
% The problem with this solution is performance, only one transaction at a time can be inevitable, and could cause a workload to execute at the speed of a single processor.
% Like with exception handling is also interesting to study how the implementation of I/O in transactional memory can effect and bound correctness, liveness, and performance theoretically and in practice.
% An overview of the difficulties associated with I/O in transactional memory is given in \cite{1364800} and \cite{10.1109/MM.2007.63}.
% 

% 
% \subsection{Cache misses}
% In his paper about efficient software transactional memory \cite{Ennals06softwaretransactional}, Enanals especially brought forward the problem of cache misses where he designed an STM that performed as few cache misses as possilbe and showed it to be much faster than other STM designs.
% One of his main claims was against obstruction free implementations where, he claims, that since they require at least one level of inderection between object metadata and actual data they introduce many cache misses.
% Cache misses are also common when there is high contention over shared objects such as a commonly accessed global counter, so cache misses and sclibility are inherently related.
% 
% Other then Ennals design \cite{Ennals05efficientsoftware}, many STMs take cache misses directly into consideration.
% RSTM \cite{Marathe06loweringthe} is an obstruction free implementation that organizes its meta and object data in a way to reduce cache misses, and SwissTM \cite{1542494} is designed for efficency where they consider the size of shared memory words and components of the STM in order to reduce cache misses.
% It could be interesting to study what components of a TM effect cache misses, and how cache misses can effect other TM properties such a scalibility.
% 
% \subsection{Non-blocking \& Obstruction-free}
% As discussed in the section of this survey on obstruction-free liveness properties, implementing a STM with locks is much more straightforward then implementing one that is obstruction-free, but obstruction freedom insures some nice properties.
% In \cite{1538908} they discuss some of the complexity required for implementing obstruction-free objects in general, which could have some implications towards how TMs should be implemneted.
% \textcolor{Red}{Need to read this paper}
% 
% The previous section shows that cache misses have been a concern as something that could hinder performance for obstruction free implementations.
% Recently what are considered and are designed as the more efficient implementations such as TL2 \cite{Dice06transactionallocking} and SwissSTM \cite{1542494} use locks.
% It is difficult to tell though if this is because lock based implementations are easier to design, or because obstruction freedom is actually inherently slower.
% Research still needs to be done on these subjects and even less is know as how to efficently implement even stronger guarentees of progress such as lock-freedom and wait-freedom.
% 
% \subsection{Kernel Modification}
% Modifying the kernal in order to better support the exection of transactions from the operating system could be important for the implementation of effective and efficient transactions.
% In \cite{1693465} they modify a linux kernel in order to better support transactional contention managment and scheduling.
% From within the OS they provide what they call \emph{serialization}, which will yield an aborted transaction from executing until its conflicting transaction has completed.
% They also provide a sort of contention managment similar to serialization that uses prioirty, so that when an aborted transaction is restarted, it is started with lower priority which is then used by the OS thread scheduler.
% They show with benchmarks that implementing these funtions in the OS is more efficient the performing them at user level.
% 
% Another mechanism implemted in the kernel is \emph{time-slice extention}, which allows a thread that is executing a transaction to request its time slice to be extended when it has expired and the OS is about to deschedule it.
% The thread can request extentions up to some maximum ammount defined by the OS.
% Desceduling a transaction during execution delays it, increasing its likelyhood to conflict with another transaction, time-slice extention tries to prevent this.
% 
% There are likely many other ways that transactional memory can be supported in the operating system, and if a mainstream OS supports some transactional memory implementation it could help lead to the wide acceptance of transactional memory.
% 

% \subsection{Choosing a conflict detection scheme}
% 
% The thought behind choosing lazy vs eager is choosing between future wasted work vs past wasted work.
% By detecting and handling a conflict as soon as possible, an eager detection scheme is attempting to avoid future wasted work by assuming the conflict and consistency criterion will most likely require that one of the transactions abort.
% On the other hand, wating as long as possible before detecting conflicts, a lazy detection scheme is attempting to avoid past wasted work hoping that most conflicts and the consistency criterion will not necessarily require a transaction to abort.
% 
% The differences between lazy and eager detection have been examined and benchmarked in quite a few different ways, but there is currently no obvious choice of one over the other.
% In fact many of the benchmakrs done so far show that the best choice depends on the worload.
% Certain implementations such as RSTM \cite{Marathe06loweringthe} are designed to support both invisible and visible reads and lazy and eager aquire, giving the programmer the freedom to choose which to use.
% They \cite{Marathe06loweringthe} run benchmarks on all different posibilities and come to the conclusion that there is no clear choice that works best in all situations.
% 
% One argument for having at least some conflicts detected eagerly is conflict managment.
% When a conflict is detected between two transaction is detected early then the conflict manager is able to choose what to do.
% Certain conflict managers have been designed to promote desirable properties so the more often and the earlier conflicts are detected the more chances a conflict manager has to promote liveness.
% 
% A recent paper \cite{1504199} has suggested using lazy detection for increased performance.
% They claim that using lazy detection promotes good livness properties such as freedom from livelock because locks are only aquired during committ time and it is unlikely that two transaction will repatibly try to commit at exaclay the same time (this is given along with other reasons).
% They perform benchmarks to support their claims.
% This works along side an additional mechanism they propose to discourage starvation.
% Another recent paper \cite{LPD-ARTICLE-2009-004} seems to support their claims.
% In this paper a mechanism called \emph{input acceptance} is proposed which measures the ammount of histories an implementation will accept for their consistency criterion.
% They show that a lazy implementation will accept more histories than an eager one, and come to the conclusion that an implementation that accepts more histories is likely to provide better performance across different workloads.
% More about input acceptance is give later in this svrvey in the section about measuring TMs.
% 
% An implementation does not have to be all lazy or all eager, for example SwissTM \cite{1542494} uses a \emph{mixed invlidation} scheme.
% They employ lazy detection of read/write conflicts in the hope that this type of conflict will often not require a necessary abort.
% Write/write conflicts on the other hand are detected eagerly on the assumption that they will most likely require one of the transactions to necessarily abort.
% 
% 
% \subsection{Implementing Conflict Detection}
% The underlying mechanisms that are used to implemt visible or invisible reads and writes and lazy or eager acquire are often used as part of the reason for choosing one or the other.  This section will go over some of the ways they can be implemented as well as some of the extentions that have been proposed.
% 
% \subsubsection{Validation for invisible reads}
% As described previously for a TM implementation that uses invisible reads each time a transaction does a read its read set must be validated, otherwise the transaction might see an inconsistent view of the memory.
% Of course the validation that needs to be done depends on the consistency condition, but here we will consider opacity because it is the most widely used  consistency condition.
% In order to perform read set validataion, every time a read occured, early STMs would check to see if every item previously read was still valid ($i.e.$ it had not been overwritten), if a value had been overwritten, then the transaction would abort.
% Each transaction then has a quadratic cost on the number of reads to perform validation, which can drastically hurt performance \cite{10.1109/TPDS.2010.49}.
% 
% \paragraph{Logical Clock / Time}
% In \cite{10.1109/TPDS.2010.49} they introduce an improvement to this called the \emph{lazy snapshot algorithm} or LSA which allows for fewer long validations.
% This algorithm uses a logical clock that is incremented each time a writing tranaction commits and the shared memory objects that are updated are assigned this clock value.
% While a transaction is active it maintains a \emph{snapshot}, or valid range of linearization points, this range is based on the shared memory objects it has read so far.
% If a transaction reads a value that is valid within its snapshot, then the value is read and the snapshot is updated with no other validation required.
% In the case that a transaction reads a value that is not valid within its snapshot it first tries to see if it can extend the range of its snapshot, in which it checks to see if each value it has read so far is still valid (similar to the normal validation process), if this succeeds the snaphot is extended and the value is read, otherwise the transaction aborts.
% They show that using the LSA improves performance over invisible reads using standard validation throughout many benchmarks.
% 
% TL2 \cite{Dice06transactionallocking} introduced a simplier, but similar clock based scheme where read validations always occur in constant time.
% It works very similar to LSA without the extensions, so TL2 will abort the transactions where the extentions would have occured.
% 
% \subsubsection{Multi-versioning}
% \emph{Multi-versioning} was introducted in \cite{1228566} as a way to prevent read only transactions from conflicting with any other transactions.
% By keeping past versions of objects a transaction only reads form the state of the memory was when it started allowing read only transactions to always commit.
% 
% Along with proposing using a clock to reduce the cost of validating invisible reads in \cite{10.1109/TPDS.2010.49} they also extend on the idea of multi-versioning with the use of clocks.
% They keep available multiple older versions of the object in the hopes of committing more read only transactions.
% In LSA if a snaphost cannont be extended to be valid for the most recent version of the object to be read, then an older version can be read that is within the snapshot if it is available.
% The more versions that are kept, the more memory overhead required by the implementation, so they suggest multiple ways of choosing the amount of versions to keep, including dynamically choosing how many current versions to keep based on if the could  be useful for any live transactions.
% Through benchmarks they find that keeping 8 versions seems to work best.
% Since then some efficency improvements have been proposed for multi-versioning such as garbage collection and \textcolor{Red}{more info, cite?}
% In \cite{1584015} they study some of the theroetical limitations of multi-versioning to be disjoint access parallel (see the section in this survey on disjoint access parallelism).
% 
% \subsubsection{Announcing for visible reads}
% In order to implement visible reads a transaction must somehow annouce to other transactions that it has read this object.
% Normally this is done by having each shared object keep a list of live transactions that have read it.
% This list is one of the main arguments against using visible reads, because it is a source of contention preventing scalablility.
% When a transaction reads a shared object it has to add itself to this shared list, and if a variable is read often there could be high levels of contention on this list, even if these are all read only transactions and have no reason to conflict.
% 
% \paragraph{RSTM}
% RSTM \cite{Marathe06loweringthe} tries to avoid this contention by keeping a limited number of visible readers in the header for each shared object, if there is a spot open a reading transaction can just perform a compare and swap opertaion to place a pointer to itself in the header.
% If there are no spots open then the transaction will read the object invisibly.
% A transaction will only have to validate the set of reads that it was not able to do visibly.
% 
% \subsubsection{Semi-visible reads}
% The idea behind semivisible reads \cite{lev:anatomy:transact:2009} is to avoid the scalibility problems of visible reads, while reducing the cost of constantly validating the read set necessary for insiible reads.
% It is implemented as an additional mechanism on top of invisible reads.
% A read counter is assigned for each shared memory object, and each time a transaction reads an object, it increases its counter, when a transaction that writes to this object committs, it resets this counter to zero.
% In addition to the read counter there is a global counter used for two things. 
% First when a transaction starts it reads and stores the value of this counter.
% Second when a transaction performs a write it increments this counter if the read counter for any of the objects it is writing are non-zero.
% Now when a transaction performs validation it checks to see if the value of the gobal counter is different than the value it had stored, and if it is unchanged then the transaction knows none of its reads have been invlidated so it can continue.
% Otherwise it performs the normal valididation for invisible reads.
% If validation succeds then it updates its stored value of the global counter to the current value.
% If validation fails it aborts.
% They expect in many read dominated workloads this will keep transactions from having to do the expensive validation process very often.
% Note that they also introduce a \emph{scalible non-zero indicator} or SNZI as a replacement for the read counter at each shared memory object that is more scalible then a traditional counter.
% 
% \subsection{Scalibility}
% As the number of cores on a processor keeps increasing every year, the scalibility of a transactional memory implementation gets more and more important.
% By design certain programs might not be able to scale well, and a programmer should take care to not create such programs, but he should not have worry that his program will not scale due to the implementation of the underlying TM system.
% As mentioned in the section on read visibility, having visible reads is worried to harm scalibility, but it is also possible for any other component of a TM implementation to become a bottle neck for scalibility and it is important examine where  these happen.
% Following this, two similar concepts, \emph{disjoint access parallelism} and \emph{conflict-based synchronization}, have been introduced as concepts for STM implementations to follow in order be scailble, but it is still unknow in many ways what exactly makes a TM scalible or not.
% 
% \subsubsection{Conflict-based Synchronization}
% Certain recent STM designs have been concerned with scalibility such as SkySTM \cite{lev:anatomy:transact:2009}, where in designing the system they take a \emph{conflict-based} approach to synchronization in order to promote scalibility.
% Conflict-based synchroniztion is defined as where contention on STM medatadata in induced only (or at least primarily) when there is contention on application data.
% If this goal is accomplished then when an application is not scaling well it is the fault of the application or the workload, and not the underlying STM implementation.
% 
% \subsubsection{Disjoint Access Parallelism}
% As a general definition, in order for a STM implementation to be \emph{disjoint access parrallel}, transactions that do not concurrently access the same shared memory location must not interfere with eachother.
% For example if every transaction accesses a global counter at creation to get its start time, then the counter becomes a point of centention for all transactions and the TM implementation is not disjoint access parallel.
% It is not always possible for a TM to be disjoint access parrallel and still be implemented in a desired way, in \cite{1584015} they examine some of these limitations.
% Specifically they show that it is not possilbe to have an implementation with invisible reads and read-only transactions that always commit and still be joint access parallel.
% They also show that a disjoint access parrallel implementation with read only transaction that always commit must write to meta data a number of times at least in the order of number of objects it reads for any transaction.
% This could be used as an argument against multi-versioning (which allows every read only transaction to commit), because ether these implementations can have visible reads and not be disjoint access parrallel, limiting scability, or they can be disjoint access parallel and perform quite a bit of work for read only transactions, which might be too much overhead for read dominated workloads which thought of as common.
% Although disjoint access parallelism is an viewed as an interesting property to study and a crucial component of scailible transactional memory, many of its other theroetical limitations remain unknown.
% 
% 










































































%=========================================================================
%=========================================================================
%=========================================================================
\section{STM computation model and base definitions}
\label{sec:model-and-conditions}

%\anote{Need to ensure this stuff is true for all the protocols}


Before getting into the content we will introduce the model of STM that will be used
by the protocols described throughout this thesis.

\subsection{Processors, Processes}
The underlying multiprocessor system executing the transactional program or application
written by a programmer is made up of one or more physical processors.
The multiprocess program, defined  by the  programmer made up of transactions is  made up  of one or
sequential processes  where each process is a separate thread of execution.
The application programmer defines the number of processes.
Each process consists of  a sequence of 
transactions (that are not known in advance) and non-transactional code
in between subsequent transactions.






%--------------------------------------------------------------------------
\subsection{Transactions and object operations}
\label{base-definitions}
% In this section we define our model for transactional memory and its operations
% that will be used when describing algorithms in this thesis.

\paragraph{Transaction}
A transaction is  a piece of code that is produced  on-line by a sequential
process (automaton)
made up of reads and writes to local memory and shared transactional objects,
that is assumed to be executed  atomically (commit) or
not  at all  (abort). This  means  that (1)  the transactions  issued by  a
process are totally ordered, and (2) the designer of a transaction does 
not have to  worry about the  management of the  base objects  accessed  
by the transaction.  Differently from  a committed transaction, an aborted  
transaction has no effect on the shared objects.

Shared objects in the system are  denoted $X,Y,\ldots$.
A transaction is able to read or write to any shared object designated
for use from within transactions.
We call these objects $t$-objects
All other (non-transactional) shared objects, denoted $nt$-objects,
are only accessible outside of transactions.
Note that this model of having separate shared objects for use only within transactions
is the one traditionally used in transactional memory
protocols, chapters \ref{chap:VWC} and \ref{chap:UC} use this model.
Separately, in chapter \ref{chap:SI} a different model is considered
because this chapter deals specifically with memory management
inside and outside of transactions (the model used is described in detail in that chapter).
The algorithms presented in chapter \ref{chap:STMlib} for use as a library are correct in either memory model,
but a separate syntax for transactional operations is used
in order to simplify the pseudo code there (this syntax is described in the chapter).

The set of the shared objects read by a transaction  defines its
{\it read  set}.  Similarly the set  of shared objects it writes  defines its 
{\it write set}. A transaction that does not  write shared objects is 
a  {\it  read-only}  transaction, otherwise it is an {\it update}
transaction.  A transaction that issues only write operations is 
a {\it write-only}  transaction. 

Transaction and the memory locations that they access
are assumed to be dynamically defined. The important point is here 
that the  underlying STM system does not know in advance the transactions. 
It is an  on-line system (as a scheduler).  



\paragraph{Operations issued by a transaction}
A transaction is started by calling the ${\sf begin\_transaction}()$ operation.
We denote operations on shared objects in the following way:
A read operation by transaction $T$ on object $X$ is denoted
$X.{\sf read}_T()$. Such an operation returns either the value $v$ read from 
$X$ or the value $abort$.  When a value $v$ is returned, 
the notation  $X.{\sf read}_T(v)$ is sometimes used.  
%
Similarly, a write operation by transaction $T$ of value $v$ into object 
$X$ is denoted $X.{\sf write}_T(v)$ (when not relevant, $v$ is omitted). 
Such an operation returns either the value $ok$ or the value $abort$. 
%

If  it  has  not  been  aborted  during a  read  or  write  operation,    a
transaction $T$ invokes  the operation ${\sf try\_to\_commit}_T()$ when 
it terminates. That operation returns $commit$ or $abort$. 





