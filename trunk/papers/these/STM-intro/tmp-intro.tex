\section{Stuff for intro}

More explicitly, an STM  is a middleware approach that provides the 
programmers  with the {\it transaction} concept  \cite{HM93,ST97}.
This  concept  is close  but  different  from  the notion  of  transactions
encountered in  databases \cite{FFGH08,HCUAGSV07,HL08}. 
A process is designed as 
(or decomposed into)  a sequence of transactions, each transaction 
being a piece  of code that, while  accessing any number of shared objects,
always appears as being executed atomically. 
The job of the programmer is only to define the units of computation that 
are the  transactions. He does not have to worry about the fact that 
the objects can be concurrently accessed by transactions. 
Except when he defines the beginning and the end of a  transaction, 
the programmer is not concerned by synchronization. It  is the job of the 
STM system to ensure that transactions execute as if they were atomic. 


Of course, a solution in which a single transaction  executes at a time
trivially implements transaction atomicity but is irrelevant from 
an efficiency point of view. So, a STM system has to do ``its best'' to 
execute and commit as many transactions  per time unit as possible. 
Similarly to 
a scheduler, a STM system is an on-line algorithm that does not know 
the future. If the STM is not trivial (i.e., it allows several transactions 
that access the same objects in a conflicting manner to run concurrently),  
this intrinsic limitation can direct it to abort some transactions in order 
to ensure both transaction  atomicity and object consistency. 
From a programming point of view, an aborted transaction has no effect (it is 
up to the process that issued an aborted transaction to re-issue it or not; 
usually, a transaction that is restarted is considered  a new transaction). 
Abort is   the price that has to  be paid by transactional  systems to cope 
with concurrency in  absence of explicit synchronization mechanisms
(such as locks or event queues).











\paragraph{Lock-based concurrent programming}
A   {\it concurrent  object} is  an   object that can be   concurrently  
accessed by different processes of a  multiprocess program. 
%
It is well known  that the design of a concurrent program is not an easy
task. To that end, base synchronization objects have been defined to help 
the programmer solve  concurrency and process cooperation  issues. 
A  major step in that direction has been 
(more than forty years  ago!) the concept of {\it mutual exclusion} \cite{D68}
that has given rise  to  the  notion of  a  {\it  lock} object.    Such an
object provides the processes with two operations (lock and unlock)
that  allows a single process at a time to access a concurrent object. 
Hence, from a  concurrent object point of view,   the  lock associated with
an object allows transforming  concurrent  accesses on  that object  
into sequential accesses.  Interestingly, all the books on synchronization 
and operating systems  have chapters on lock-based
synchronization. In addition, according to the abstraction level
supplied to the programmer,  a lock may be encapsulated into a linguistic 
construct such as a {\it monitor} \cite{H74} or a {\it serializer} \cite{HA79}.



Unfortunately locks have drawbacks. One is related to the  granularity
of the object protected by a lock. More precisely, if several data items 
are encapsulated  in a single  concurrent  object, the
inherent parallelism  the object can provide 
can be drastically reduced. This  is for example the case of a queue 
object for which concurrent executions of enqueue and dequeue operations 
should be possible as long as they are not on the same item.
Of  course  a   solution  could  consist of  considering  each item of the
queue as  a concurrent object, but in that case, the  operations  enqueue  
and  dequeue  can  become very   difficult  to  design and implement. 
More severe  drawbacks associated with locks lie in the fact that 
lock-based operations are deadlock-prone and cannot be easily composed. 

Hence  the question:  how to  ease  the  job of  the programmer  of
concurrent applications?
A (partial)  solution consists of providing her/him with an appropriate 
library where  (s)he  can  find  correct  and  efficient  implementations  of  
the most popular concurrent data structures (e.g., \cite{HS08,MS96}). 
Albeit very attractive, this approach does not solve entirely the problem  
as it does not allow the programmer to define  specific concurrent objects 
that take into account  her/his particular  synchronization issues. 


\paragraph{The Software Transactional Memory approach}
The concept of {\it Software Transactional  Memory}   (STM)  is  an answer  
to   the  previous  challenge.   The notion  of   transactional  memory  was
first   proposed  (nearly twenty years ago!) by Herlihy  and Moss to 
implement concurrent  data structures  \cite{HM93}.  It  has  then  been 
implemented in software  by Shavit  and  Touitou   \cite{ST97} and  has
recently gained great  momentum as  a promising alternative  to locks in
concurrent programming  \cite{FFGH08,H07,LK08,R08}. Interestingly  enough,  
it is important to also observe that the recent advent of multicore 
architectures has  given rise to what is called the {\it multicore  
revolution} \cite{HL08} that has  rang the revival of concurrent programming. 



Transactional  memory   abstracts away the  complexity associated with 
concurrent programming    by  replacing locking  with  atomic
execution units. In  that way, the programmer has to focus on  where 
atomicity is required and  not on the  way it must be realized. The aim of
an STM system is consequently  to  discharge the programmer from the direct 
management of the synchronization that is entailed by  accesses  to concurrent  objects. 

More generally,  STM  is a middleware approach that provides the 
programmers  with the {\it transaction} concept (this concept 
is close but different from the notion of transactions encountered in 
database systems \cite{FFGH08}). A process is designed as 
(or decomposed into)  a sequence of transactions, with each transaction 
being a piece  of code that, while  accessing  concurrent  objects, 
always  appears as if it was  executed atomically\footnote{Actually,  
while the word {``\it transaction}'' has historical roots, it seems that 
{``\it atomic procedure}'' would be more appropriate because 
``transactions''  of STM systems are  computer science objects 
that are different  from database transactions.  We nevertheless 
continue using the word  {``\it transaction}'' for historical reasons.}.
The job of the programmer is only to state which  units of computation
have  to be atomic.  He does not have to worry about the fact that the 
objects accessed by  a transaction can be concurrently accessed. 
The programmer is not concerned by synchronization
except when (s)he defines the beginning and the end of a  transaction.
It  is then the job of the 
STM system to ensure that transactions are executed as if they were atomic. 



Let us observe that  the ``spirit/design philosophy'' that has given 
rise to  STM systems is not new: it is related to the notion of 
{\it abstraction level}.   
More precisely,  the  aim  is   to allow  the programmer  to  focus and
concentrate only  on the problem  (s)he has to
solve and not on the base machinery needed to solve it. 
As we can see, this is the approach  that  has   replaced assembly languages  
by  high level languages and programmer-defined garbage collection 
by automatic garbage collection.   STM can  be seen as a  new concept
that takes  up  this challenge when considering synchronization issues. 





















\paragraph{Lock-based concurrent programming}
A   {\it concurrent  object} is  an   object that can be   concurrently  
accessed by different processes of a  multiprocess program. 
%
It is well known  that the design of a concurrent program is not an easy
task. To that end, base synchronization objects have been defined to help 
the programmer solve  concurrency and process cooperation  issues. 
A  major step in that direction has been 
(more than forty years  ago!) the concept of {\it mutual exclusion} \cite{D68}
that has given rise  to  the  notion of  a  {\it  lock} object.    Such an
object provides the processes with two operations (lock and unlock)
that  allow a single process at a time to access a concurrent object. 
Hence, from a  concurrent object point of view,   the  lock associated with
an object allows transforming  concurrent  accesses on  that object  
into sequential accesses.  Interestingly, all the books on synchronization 
and operating systems  have chapters on lock-based
synchronization. In addition, according to the abstraction level
supplied to the programmer,  a lock may be encapsulated into a linguistic 
construct such as a {\it monitor} \cite{H74} or a {\it serializer} \cite{HA79}.



Unfortunately locks have drawbacks. One is related to the  granularity
of the object protected by a lock. More precisely, if several data items 
are encapsulated  in a single  concurrent  object, the
inherent parallelism  the object can provide 
can be drastically reduced. This  is for example the case of a queue 
object for which concurrent executions of enqueue and dequeue operations 
should be possible as long as they are not on the same item.
Of  course  a   solution  could  consist of  considering  each item of the
queue as  a concurrent object, but in that case, the  operations  enqueue  
and  dequeue  can  become very   difficult  to  design and implement. 
More severe  drawbacks associated with locks lie in the fact that 
lock-based operations are deadlock-prone and cannot be easily composed. 

Hence  the question:  how to  ease  the  job of  the programmer  of
concurrent applications?
A (partial)  solution consists of providing her/him with an appropriate 
library where  (s)he  can  find  correct  and  efficient  implementations  of  
the most popular concurrent data structures (e.g., \cite{HS08,MS96}). 
Albeit very attractive, this approach does not solve entirely the problem  
as it does not allow the programmer to define  specific concurrent objects 
that take into account  her/his particular  synchronization issues. 


\paragraph{The Software Transactional Memory approach}
The concept of {\it Software Transactional  Memory}   (STM)  is  an answer  
to   the  previous  challenge.   The notion  of   transactional  memory  was
first   proposed  (nearly twenty years ago!) by Herlihy  and Moss to 
implement concurrent  data structures  \cite{HM93}.  It  has  then  been 
implemented in software  by Shavit  and  Touitou   \cite{ST97} and  has
recently gained great  momentum as  a promising alternative  to locks in
concurrent programming  \cite{FFGH08,H07,LK08,R08}. Interestingly  enough,  
it is important to also observe that the recent advent of multicore 
architectures has  given rise to what is called the {\it multicore  
revolution} \cite{HL08} that has  rang the revival of concurrent programming. 



Transactional  memory   abstracts away the  complexity associated with 
concurrent programming    by  replacing locking  with  atomic
execution units. In  that way, the programmer has to focus on  where 
atomicity is required and  not on the  way it must be realized. The aim of
an STM system is consequently  to  discharge the programmer from the direct 
management  of  the  synchronization  that  is entailed  by   accesses   to
concurrent  objects.  

More generally,  STM  is a middleware approach that provides the 
programmers  with the {\it transaction} concept (this concept 
is close but different from the notion of transactions encountered in 
database systems \cite{FFGH08}). A process is designed as 
(or decomposed into)  a sequence of transactions, with each transaction 
being a piece  of code that, while  accessing  concurrent  objects, 
always  appears as if it was  executed atomically\footnote{Actually,  
while the word {``\it transaction}'' has historical roots, it seems that 
{``\it atomic procedure}'' would be more appropriate because 
``transactions''  of STM systems are  computer science objects 
that are different  from database transactions.  We nevertheless 
continue using the word  {``\it transaction}'' for historical reasons.}.
The job of the programmer is only to state which  units of computation
have  to be atomic.  He does not have to worry about the fact that the 
objects accessed by  a transaction can be concurrently accessed. 
The programmer is not concerned by synchronization
except when (s)he defines the beginning and the end of a  transaction.
It  is then the job of the 
STM system to ensure that transactions are executed as if they were atomic. 



Let us observe that  the ``spirit/design philosophy'' that has given 
rise to  STM systems is not new: it is related to the notion of 
{\it abstraction level}.   
More precisely,  the  aim  is   to allow  the programmer  to  focus and
concentrate only  on the problem  (s)he has to
solve and not on the base machinery needed to solve it. 
As we can see, this is the approach  that  has   replaced assembly languages  
by  high level languages and programmer-defined garbage collection 
by automatic garbage collection.   STM can  be seen as a  new concept
that takes  up  this challenge when considering synchronization issues. 


%\vspace{-0.1cm}
\paragraph{The state of affairs and  related works}
Of course, a solution in which a single transaction is executed at a time 
trivially implements transaction atomicity, but is inefficient
on a multiprocessor system (as it allows only non-transactional code 
 to execute in parallel).   Instead, an STM system has to allow 
several transactions to execute  concurrently, but then it is possible that
they access the same concurrent objects in a conflicting manner.
In that case
some  of  these  transactions might  have  to   be  aborted. Hence,  in  a
classical  STM system    there    is  an    {\it   abort/commit}    notion
associated   with transactions. 









\paragraph{STM Systems.}
Transactional Memory (TM) \cite{herlihy93,shavit95} has  emerged  as  an  attempt  to allow  concurrent  programming  based  
on sequential reasoning:  By  using  TM,  a  user  should  be able  to  write  a  correct  concurrent application, provided she can  
create a correct  sequential program. The underlying TM  system takes care of  the correct  implementation of  concurrency.  
However,  while most existing  TM algorithms consider applications  where  shared  memory  will  be  accessed  solely by  code  
enclosed  in a transaction,  it still seems   imperative to  examine the  possibility that memory is accessed both inside and outside 
of transactions.















%=========================================================================
%=========================================================================
%=========================================================================
\section{STM computation model and base definitions}
\label{sec:model-and-conditions}



\subsection{Processes  and atomic shared objects}
An application is made up of  an  arbitrary number  of  processes  and  $m$
shared  objects.  The processes are denoted $p_i$, $p_j$, etc., 
while the  objects are  denoted $X,Y,\ldots$, where each id $X$ is such 
that $X \in \{1,\cdots,m\}$.   Each process consists of  a sequence of 
transactions (that are not known in advance).

Each of the $m$ shared objects is an atomic read/write object. 
This means  that the read and  write operations issued on  such an  object
$X$  appear as  if they have  been executed  sequentially, and this 
``witness sequence'' is  legal (a read returns the value written by the  
closest write  that precedes it in this sequence) and respects the real time 
occurrence  order on the operations on $X$ (if  $op1(X)$  terminates  before
$op2(X)$  starts, $op1$ appears before $op2$ in the witness sequence 
associated with $X$). 




%--------------------------------------------------------------------------
\subsection{Transactions and object operations}
\label{base-definitions}
In this section we define our model for transactional memory and its operations
that will be used when describing algorithms in this thesis.

\paragraph{Transaction}
A transaction is  a piece of code that is produced  on-line by a sequential
process (automaton), that is assumed to be executed  atomically (commit) or
not  at all  (abort). This  means  that (1)  the transactions  issued by  a
process are totally ordered, and (2) the designer of a transaction does 
not have to  worry about the  management of the  base objects  accessed  
by the transaction.  Differently from  a committed transaction, an aborted  
transaction has no effect on the shared objects. 
A transaction  can read or to write any shared object. 
 

The set of the objects read by a transaction  defines its
{\it read  set}.  Similarly the set  of objects it writes  defines its 
{\it write set}. A transaction that does not  write shared objects is 
a  {\it  read-only}  transaction, otherwise it is an {\it update}
transaction.  A transaction that issues only write operations is 
a {\it write-only}  transaction. 

Transaction are assumed to be dynamically defined. The important point is here 
that the  underlying STM system does not know in advance the transactions. 
It is an  on-line system (as a scheduler).  



\paragraph{Operations issued by a transaction}
We denote operations on shared objects in the following way.
A read operation by transaction $T$ on object $X$ is denoted
$X.{\sf read}_T()$. Such an operation returns either the value $v$ read from 
$X$ or the value $abort$.  When a value $v$ is returned, 
the notation  $X.{\sf read}_T(v)$ is sometimes used.  
%
Similarly, a write operation by transaction $T$ of value $v$ into object 
$X$ is denoted $X.{\sf write}_T(v)$ (when not relevant, $v$ is omitted). 
Such an operation returns either the value $ok$ or the value $abort$. 
%
The notations $\exists~ X.{\sf read}_T(v)$  and $\exists~ X.{\sf write}_T(v)$ 
are  used as  predicates to  state whether a transaction  $T$ has issued a
corresponding read or write operation. 


If  it  has  not  been  aborted  during a  read  or  write  operation,    a
transaction $T$ invokes  the operation ${\sf try\_to\_commit}_T()$ when 
it terminates. That operation returns it $commit$ or $abort$. 



\paragraph{Incremental snapshot}
As  in \cite{BSW79},  we assume  that the behavior of a transaction $T$  
can be decomposed in  three sequential steps:  
it first reads  data objects,  then does local computations and 
finally   writes  new values  in some  objects, which means
that  a  transaction can  be  seen as  a software 
${\sf read\_modify\_write()}$ operation that is 
dynamically defined  by  a process. (This model is for 
reasoning, understand and  state properties on STM systems.  
It only requires that everything appears as described  in the model.)


The read set is  defined  incrementally,  which  means  that a 
transaction  reads  the objects of  its read set  asynchronously  one after
the other (between  two consecutive reads, the transaction 
can  issue local  computations   that  take  arbitrary, but finite,
durations). We  say  that the  transaction $T$ computes an  {\it incremental
snapshot}.  This snapshot has to be {\it consistent} which
means that there is a time frame in which these values have co-existed 
(as we will see later, different consistency conditions consider different  
time frame  notions). 

If it reads  a  new  object whose  current  value makes  inconsistent  its 
incremental snapshot, the transaction   is  directed to  abort. 
If the transaction is not aborted during its read 
phase, $T$ issues local computations. Finally,  if the transaction  is  
an update transaction, and its  write operations  can be issued 
in  such a way that the transaction  appears as  being executed
atomically,   the objects of its write set are updated  and the transaction
 commits.   Otherwise, it  is  aborted.

\paragraph{Read prefix of an aborted transaction}
A read prefix is associated with every transaction that aborts.
This read prefix contains all its read operations if the transaction 
has not been aborted  during its read phase.  If it has been  aborted during 
its read phase, its read prefix contains all read operations it has issued 
before the read that entailed the abort.  Let us observe that the values 
obtained by the read operations of the read prefix of an aborted transaction 
are mutually consistent (they are from a consistent global state). 


%---------------------------------------------------------------------------
\Xomit{%  OMITTED%%%%%%%%%%%
\subsection{The incremental read + deferred update model}
In this transaction system model, each transaction $T$ uses a local working
space.  
When  $T$ invokes $X.{\sf  read}_T()$  for  the first   time, it  reads the
value of $X$ from  the shared  memory and copies it into its  local working
space. Later  $X.{\sf  read}_T()$ invocations  (if any)  use this copy.
So, if $T$  reads $X$ and then $Y$, these reads  are done incrementally, and
the state of the shared memory may  have changed in between. 
As already said, one usually says  that the  transaction $T$ 
computes an  {\it incremental snapshot}.


When  $T$ invokes $X.{\sf write}_T(v)$,  it writes  $v$ into  its working
space (and does not access the  shared memory). 
Finally, if $T$ is not aborted, 
it copies  the values written (if  any) from its
local working  space to  the shared memory.  (A  similar   deferred  update
model  is used  in some  database transaction systems.)  
} % end of omit 