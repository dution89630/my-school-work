\documentclass[10pt]{sigplanconf}

\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{amsmath,amsfonts,amssymb,latexsym}
\usepackage{txfonts,pxfonts,wasysym}
%\usepackage[T1]{fontenc}
\usepackage{color}
\usepackage{flushend}
\usepackage{multicol}
\usepackage{cite}

\usepackage{macros}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage{ioa_code}

\newcommand{\vincent}[1]{{\bf [V: #1]}}
\newcommand{\michel}[1]{{\bf [M: #1]}}
\newcommand{\tyler}[1]{{\bf [T: #1]}}

\begin{document}

\title{Transaction-Friendly Binary Search Tree}

\authorinfo{\mbox{Tyler Crain}}
           {INRIA Rennes Bretagne Atlantique}
           {tyler.crain@irisa.fr}

\authorinfo{\mbox{Vincent Gramoli}}
           {EPFL\\Switzerland}
           {vincent.gramoli@epfl.ch}

\authorinfo{\mbox{Michel Raynal}}
           {University of Rennes 1\\France}
           {raynal@irisa.fr}

%%%%%%%%%%%%%%%

\newpage

\maketitle

\setcounter{page}{1}

\begin{abstract}
Transactions are fundamentally different from locks and present high overhead in usual concurrent data structures. 
We propose a programming technique to derive \emph{transaction-friendly data structures} and demonstrate the performance benefit of a 
transaction-friendly binary search tree.
\end{abstract}

\section{Introduction}

Transactions simplify concurrent programming by guaranteeing the programmer 
that all statements delimited within a transaction execute atomically.
Hence, a programmer who builds upon an existing transactional library 
is guaranteed to obtain new operations that execute atomically.
As far as we know, all existing transactional library used in the 
literature are naively derived from sequential code, thus hampering their 
efficiency.
In this paper, we present \emph{transaction-friendly data structures} as 
data structures with the aim of being accessed through speculative executions.

A transaction-friendly data structure is a crucial building block of 
concurrent transactional libraries. They provide a minimal toolbox a 
programmer can rely on to write a concurrent application easily.
Although implementing transaction-friendly data structures requires some skills 
in concurrent programming, using them to write a concurrent applications 
does not requires such skills. The benefit of using a 
transaction-friendly data structure instead of a transactionalized sequential 
data structure is to convey high performance to overlying applications.

Popular binary search trees, like red-black trees, have been extensively 
studied to evaluate the performance of TMs~\cite{ST95,HLMS03,HK08,FFR08,DFGG11}.
Binary search trees are, however, not TM-friendly for at least three reasons. 
First, they rely on rebalancing, a global operation that should not be 
executed speculatively. Second, their implementation often rely on sentinel 
nodes that produce false-conflicts between concurrent transactions. Three, 
a rotation may abort an inverted rotation even though they could compensate 
each other.

Our methodology to implement a TM-friendly data structure relies on the following rules:
\begin{itemize}
	\item Use non-transactional accesses when possible. Although compilers with TM support\footnote{Intel C++ STM Compiler.\\http://software.intel.com/en-us/articles/intel-c-stm-compiler-prototype-edition/} can get rid of 
	unnecessary meta-data overhead for accesses to thread-private variables, they cannot identify memory accesses that do not need to 
	be transactionalized from the point-of-view of the application programmer.
	\item Shorten the transactions as much as possible. This is often the case that a single operation, which should appear as executing 
	atomically, does not need to be encapsulated in a single transaction but can be encapsulated in multiple transactions. This observation raises the issue
	of nesting a multiple-transaction operation inside another transaction: should we consider these two transactions independently
	for efficiency reasons or should we consider that they are part of the outermost transaction (in a flat-nested manner) to ensure 
	extensibility?
	\item Re-thing the data structure to be able to shorten the transactions further.
	%\item Logical deletion techniques~\cite{Har01,Mic02}?
\end{itemize}
We illustrate these choices by describing a new binary search tree algorithm
that is transaction-friendly. We evaluate it experimentally inside the 
STAMP benchmark suite~\cite{CCKO08}.  

%\section{Problem}
%
%To motivate the implementation of TM-friendly data structures, take a skip list implementation of an integer set.
%The skip list stores integers in a sorted order and supports $\lit{insert}$, $\lit{delete}$ and $\lit{contains}$ operations.
%Such data structure is appealing as it guarantees logarithmic time complexity and it is generally simpler than alternative binary trees.
%
%
%\section{Binary Trees}
%
%\section{Hash Tables}
%
%The bucket hash table from Michael~\ref{Mic02} provides lock-free constant time operations to insert, 
%delete and search for a specified element. When a common key maps to several value, these values are stored
%in the same bucket implemented as a bucket hash table. 
%
%Transactional operations acting on linked lists are unfortunately known to suffer from false conflicts, 
%as one update on the head of the list can invalidate
%a concurrent search that is paring the tail of this list and that is about to commit~\cite{FGG09}.



%\section{Motivation}
\subsection*{Balanced Binary Trees}
Balanced binary trees such as red-black trees \ref{} and AVL \ref{} trees are classical data structures that provide good performance.
In order to ensure this performance they must keep the tree balanced, and because of this an insert or delete operation is not as simple as adding or removing a node from the bottom of the tree.
A node with two children that is to be deleted must find a successor node from the bottom of the tree to take its place.
Both inserts and deletes often require rotations that could perform modifications to a large part of the tree.
In order to ensure linearizability with these operations when put in a parallel context this means locking possibility large section of the trees or having a large read/write set in the case of transactions.
\subsection*{Where conflicts occur}
First note that in order to execute an insert/delete operation a search must be done to find the appropriate location in the tree before the insert/delete is performed.
Therefore an insert or delete operation could be thought of as a search $+$ insert or a search $+$ delete operation.
Now consider when an node is inserted or deleted, in order to keep the tree balanced rotations might be necessary, starting from the position of insertion/deletion and possibly going all the way up to the root.
Rotations and searches cannot run concurrently because if a search is pre-empted on a node that is rotated downwards the search might miss the location it is looking for.
In addition, a group of rotations done by an insert/delete cannot run concurrently with another group of rotations done by a different insert/delete because one set might unbalance the other.
Given this the only two operations that are guaranteed to not conflict with each other are two searches, any other group of operations could conflict with each other even if the nodes they are searching/modifying
are in completely different corners of the tree.

Without considering rotations, a search cannot run concurrently with a delete because the search might be per-empted on a node that is removed from the tree, leaving the search with undefined or incorrect results.

In order to insure linearizability while considering these conflicts the operations require locking large sections of the tree or (in the case of transactional memory) having large read/write sets, which, in either case limits concurrency.
This leads to the design of modified binary tree algorithms specialized for concurrency.

\subsection*{Transactional AVL-Tree}

The benefit of STM is that an unmodified sequential algorithm can be placed (more or less) directly in transactions and work concurrently.
The problem with this though is, as discussed above, these algorithms were not designed for concurrency and provide possibly unnecessary conflicts.
There have been mechanisms introduced for STM to provide ways of creating more efficient implementations.
For example ${\mathcal E}$-STM~\cite{FGG09} provides a more efficient 
way of implementing search structures, and release operations~\cite{HLMS03} 
provide the programmer with the possibility to remove items from his read set 
for efficiency reasons.
Those works provide the programmer mechanisms to develop more efficient transactional code, which differs from this work because the goal here is to provide a correct and efficient concurrent data
structure that can be used directly by programmers as a library in their transactions.
This paper will show that creating such a library is not an obvious task.
The hope of Transactional Memory is that any programmer may be able to create an implementation of a classic AVL or red-black tree in transactional code, but as this paper will show
there are much more efficient ways to implement a tree search structure in that is compatible with transactions, and these structures become more complicated.

Designing parallel data structures is not a new field and there are many different implementations, but unfortunately are not designed to be directly usable within transactions.
Even so, many of the concepts from this previous work can be applied in transactions.
The following paragraphs describe two fairly recent implementations of \emph{AVL-trees} that strongly influence the design of the algorithm presented in this paper.

\section{Related Work}

\subsection{Locally-rotating AVL-Tree}
The first algorithm was proposed by Boug\'e et al. in \ref{IRISAppr}.
It is a modified version of a relaxed AVL tree.
A relaxed AVL tree is one that is not guaranteed to be perfectly balanced at all times.
This algorithm introduces local rotation and delete operations that differ from the standard AVL operations.
In order to increase concurrency these local operations lock a minimal amount of nodes.
The delete is done by locking just the node to be deleted and instead of immediately removing the node from the tree it is marked to be removed later.
Nodes marked for removal are then rotated downwards until they become leaves, at which point they are removed.
Rotations are local operations, each rotation is done one rotation at a time, only locking the nodes that are being rotated.
An important property of these local operations is that performing them on an unbalanced tree containing nodes marked for removal will eventually result in a balanced tree containing no nodes marked for removal.

The key to ensuring the eventual balance of the tree is that each node keeps its own information about the heights of its left and right sub-trees.
This information is used by the local operation \emph{propagate} which moves this balance information from the leaves to the root.
As long as a leaf knows that it has no children, the correct height of the tree will be propagated up to the root.
Concurrently with the propagations, appropriate rotations and removals are performed.

A few more modifications are made in order to ensure the linerizability of the search/insert/delete operations.
In order to solve the problem of a search operation that is per-empted on a node that is concurrently rotated down the algorithm is modified as follows.
As a search operation traverses tree at each node it reaches it adds a marker to the node alerting concurrent threads to not perform a rotation on the node.
The marker is then removed after the search moves to the next node.

\subsection{Optimistic AVL-Tree}
A more recent paper~\cite{BCCO10} creates a practical implementation of the algorithm proposed by Boug\'e~\cite{IRISAppr}.
In order to increase efficiency it makes several modifications to the original algorithm.
Nodes marked for removal are not rotated down the tree, they are left alone until (if) they have one or no children at which point they are removed.
Of course this means in the worst case all but the leaves of the tree could be marked for removal and not actually removed, but they find that in practice the tree does not grow too large with these nodes.

In order to reduce the amount of writes done to shared memory, this tree avoids the procedure used by Boug\'e et al. of keeping a list at each node of the search operations traveling through it.
Instead, a search keeps track of the nodes it has visited (through the use of recursion), and once it sees that it is on a node that has been rotated downwards the search rolls back to a valid location.

\subsection{Transactional Compatibility}
Unfortunately even though these algorithms are nice they cannot be directly placed into transactions and work efficiently.
Firstly, both the algorithms require locking mechanisms and use techniques such as hand over hand locking.
Secondly, in order to ensure the correctness of searches, \ref{IRISAppr} performs a two writes (an insert and remove) to each node it traverses, while \ref{BCCO10} performs a partial rollback when it discovers its search has been invalidated.
Even though it might be possible to implement any of these techniques in transactions, it is not obvious how to do then efficiently and correctly.
Instead what is done here is similar techniques are used, but are modified to be compatible, efficient, and correct when implemented in transactions.

%\subsection{Concepts for efficient TM Algorithm design}
\section{Methodology for TM-Friendly Data Structures}

\subsection{Minimal read/write set size}
Concurrency in a TM is limited by conflicts, conflicts are created when concurrent transactions read and write to the same value.
In order to reduce conflicts the read and write sets of a transaction should be as small as possible.
Since the intention of the data structure is to be used as a library, a programmer will be able to nest the operations within his own tree, and it is likely he will even perform multiple operations on the same data structure from within the same transaction.
For example he may perform a search, an insert, and a delete all from within the same transaction.
In this case it is even more important to keep the read and write sets as small as possible.
Consider if a programmer was to use a traditional red-black tree in his transaction.
After each operation on the tree the combined size of the read/write set will increase by as much as $O(\log{n})$ (where $n$ is the number of nodes in the tree).
In addition to this, even if the search is far down the tree, some of those memory locations in the read/write set will be from nodes that are close to the root, and any modification to a node close to the root would likely
abort a large amount of concurrent transactions.

Luckily, using a more efficient algorithm, the size of the read/write set of a transaction with nested operations
can be kept at a size of $O(k)$ instead of $O(k\log{n})$ (where $k$ is the number of nested insert/delete/search operations in a transaction).
Consider the search/insert/delete operations without rotations, all three of them do the following.
First they perform a search to find a location in the tree, then they perform some operation on this location (and no operation in the case of search).
A classic AVL/red-black tree implementation in transactional memory would preform transactional reads from the root all the way down to the node being searched for, then perform some additional reads/writes to complete the insertion/deletions.
It turns out that having most of these reads in the read set is unnecessary.
For example a search that is successful only needs to ensure that the node is still in the tree when the transaction commits, it does not care about the other nodes that it traversed before it found the correct node.
This can be easily insured by having the pointer from the parent node to the correct node in the transaction's read set.
A search that fails only needs to ensure that the node it is searching for is not in the tree when the transaction commits, this can be insured by simply making sure that the pointer from the parent that would point to it is $\bot$
(i.e. that pointer is in the read set of the transaction and its value is $\bot$).
Similar concepts can be used for the insert and delete operations.
Using this technique each operation will only increase the size of the read/write set by a constant amount, keeping the size of the sets much smaller, decreasing the chance of conflicts with concurrent transactions.

\subsection{Avoiding expensive transactional reads}
Conflicts are not the only reason to keep the reads set small.
Transactional reads are expensive to perform.
In addition to keeping track of the reads done so far, during each read an STM with visible reads will write to shared memory
and an STM with invisible reads will perform validations at the worst case of cost $O(n^2)$ 
(here $n$ is the size of the read set).

In order to implement an efficient algorithm it is necessary to have more than just the traditional transactional $read$ and $write$ operations provided by TM, some additional mechanisms are needed.
A famous example of such a mechanism is the early $release$ proposed with 
DSTM~\cite{HLMS03}.
Early $release$ allows the programmer to remove previously read locations from the read set.
This allows the programmer to decrease the size of the read set in order to reduce conflicts and validation costs.
Even though this can improve performance, the initial cost of performing the transactional read is not changed using early $release$ so an even more efficient mechanism can be used called the $unit$ read.
A $unit$ read can be simply thought of as a read that does not preform validation and does not get added to the transaction's $read$ set.
A $unit$ read returns the most recent value written to memory by a  committed transaction.
This allows access to the tree without increasing the size of the transaction's read set and without performing validations thereby reducing conflicts and increasing performance.

As described in the previous section, when searching for a node, most of the locations read do not need to be added to the read set, this is where $unit$ reads come in.
When traversing the tree trying to find the correct node unit reads are used, once the correct node is found normal transactional reads are performed on the appropriate locations in order to ensure linearizability.
The section describing the algorithm will show how this is done.

\subsection{Minimal operation size}
The longer a transaction keeps an item in its read/write set the more likely it is to conflict with another transaction, so transactions should be kept as short as necessary.
\subsubsection{Rotations}
Using mechanisms to avoid performing expensive reads where possible is important, but pointless if a single transaction does a large amount of modification to the data structure.
For example even if unit reads are used to find the location of where to insert a node, if the insert then performs a large amount of rotations
the read/write set will become large none the less.
Notice that the operations such as rotations are not required to ensure the linearizability of the insert/delete/search operations.
Because of this it is not necessary to perform rotations in the same transaction as the insert or delete.
Rotations can be performed separately in their own transactions.
This becomes even more important when multiple operations to the tree are nested within the same transaction.
For example consider two insert operations that are nested within a single transaction, at the worst case one might be inserted in one corner of the tree
and the second is inserted at the other corner of the tree, and both perform rotations from their location all the way up to the root.
Now even if unit reads are used to find their location, the transaction will still be performing reads and writes on a large portion of the tree creating many unnecessary conflicts.

As described in the related work section \ref{IRISAppr} describes a way to perform local rotations.
This technique uses two local operations $rotate$ and $propogate$ in order to ensure that the tree is eventually balanced.
The same technique is used here, allowing the rotations to be performed outside of the insert/delete operations, and each local rotation being a single transaction.
Each local propagation is also performed as a single transaction.
Keeping the insert/delete/search and rotate/propagate operations as small as possible allow more operations to execute at the same time without conflicts, increasing concurrency.

Increased concurrency is not the only reason for local rotations.
In a non-concurrent implementation, a single insert/delete might warrant a large amount of rotations going up the tree from the location of the insert/delete,
keeping the tree balanced so that the searches are efficient.
This is not always the case in a concurrent implementation.
Given that keeping the size of operations minimal this allows many inserts and deletes to take place at the same time in different locations of the tree.
Each of these might require a certain set of rotations to balance the tree, but because the operations are happening concurrently the appropriate rotations to balance the tree are constantly changing
and since each operation only has a local view of the tree it might not know what the appropriate rotations are.
If each set of rotations is performed in a single transaction the sets are more likely to conflict or even undo each other's rotations.
With local rotations, each time a rotation is performed the most up to date local information is used, avoiding repeating rotations at the same location.

\subsubsection{Deletions}
The classical AVL/red-black tree deletions can access and require locking a large amount of the tree.
When a node that is removed that is not a leaf, a successor needs to be found from the bottom of the tree, performing reads on all the way to the leaf, incurring a worst case
read set size of $O(\log{n})$ (where $n$ is the number of nodes in the tree).
A simple way to minimize the amount of the tree accessed during the delete is used in \ref{IRISAppr} and \ref{BCCO10}.
If the node is a leaf then it is just immediately removed from the tree.
Otherwise instead of finding a successor, the node is just marked as $deleted$ and is then removed later.
Using this technique along with $unit$ reads for the search the size of the read set becomes $O(1)$.

The danger with this is the tree might grow too large with nodes that are marked as deleted, slowing down search time, solutions to this will be
described later.


\section{TM-Friendly Tree Algorithm}
%
%\begin{algorithm}[!ht]%\label{alg:tm}
%  \caption{Naive TM for transaction $t$.}
%  \begin{algorithmic}[1]
%  	%\begin{multicols}{2}
%   {\size 
%   		\Part{$\act{begin}()_t$}{
%   			\State $\ms{r-set} \gets \emptyset$
%   			\State $\ms{w-set} \gets \emptyset$
%   			\State $\ms{w-log} \gets \emptyset$
%   		}\EndPart
%   	
%		\Statex   	
%   	
%		\Part{$\act{write}(x,v)_t$}{
%			\If{$\tup{x,v'}\notin \ms{w-set}$}
%				\While{$!\lit{cas}(\act{lock}(x), \lit{unlocked}, \lit{locked})$}
%					\State $\lit{abort-and-restart}$() \label{line:abort1} \Comment{contention mgmt} 
%				\EndWhile
%				\State $\ms{w-log} = \ms{w-log} \cup \{\tup{x, \lit{store}(x,v)}\}$
%				\State $\ms{w-set} = \ms{w-set} \cup \{\tup{x, v}\}$
%			\EndIf
%			\State $\act{return}(\lit{ok})$
%		}\EndPart
%		
%		\Statex
%		
%		\Part{$\act{read}(x)_t$}{
%			\If{$\tup{x,*}\notin \ms{w-set}$}
%				\While{$!\lit{cas}(\act{lock}(x), \lit{unlocked}, \lit{locked})$}
%					\State $\lit{abort-and-restart}$()	\label{line:abort2} \Comment{contention mgmt} 
%				\EndWhile
%				\State $v = \act{load}(x)$
%				\State $\ms{r-set} = \ms{r-set} \cup \{\tup{x, v}\}$
%			\Else{} let $v$ be such that $\tup{x,v}\in \ms{w-set}$
%			\EndIf
%			\State $\act{return}(v)$
%		}\EndPart
%		
%		\Statex		
%		
%   		\Part{$\act{commit}()_t$}{
%   			\For{$\tup{x,*} \in \ms{w-set}$} $\act{unlock}(x)$ \EndFor
%   		}\EndPart
%	}
%	%\end{multicols}
%  \end{algorithmic}
%\end{algorithm}

\subsection{Node Structure}

\subsection{Tree Operations}
Here we will describe how the standard map operations are implemented.
Each of these (except the find) are implemented as normal transactions allowing the programmer to use them in their own transactions.

{\bf Find} The find procedure cannot be called directly by the programmer, but instead is used by the $search$, $insert$, and $delete$ operations.
It is very similar to a traversal of a normal binary tree.
Starting from the node provided to the procedure it continues until it either finds a node with the same key it is searching for or it reaches a leaf returning the node/leaf.
The interesting point here is that the search continues until it finds a node with the $removed$ flag set to false.
We will show later that any node with the $removed$ flag set to true will always have $2$ children.
It is interesting to note that since the find procedure only uses unit reads it will never cause an abort.

{\bf Search} The search operation uses the ${\sf find}$ procedure to locate the node starting from the root.
Once the node has been found it performs a normal transactional read of the $removed$ flag to ensure that the node is not removed at least until the transaction commits (this is necessary because the after the unit read done by the $find$ operation and before the normal read done here some other transaction could have removed the node).
If $remove$ is $true$ then find is executed again, except instead of starting from the root, it starts from this node.
It the key of the node is equal to the key being searched for it performs a transactional read of the $deleted$ flag, if the flag is $false$ the search operation returns $true$, otherwise it returns $false$.
If the key of the returned node is not equal to the key being searched for then a read is performed on the child pointer of the returned node where the node with the key being search for would be expected to be.
If the value of the pointer is $\bot$ then $false$ is returned, otherwise the find operation is performed again starting from this node.

{\bf Get} The get operation is the same as the ${\sf find}$ operation except that instead of returning $true$ or $false$ it returns the $value$ field of the node found or $\bot$ if no node was found.

{\bf Insert} Similar to the $search$ operation the $insert$ operation uses the $find$ procedure until it finds a node that has not been removed (checking the $removed$ flag using a transactional read).
If a node is found with the same $key$ as the one being searched for then the $deleted$ flag is checked.
If the flag is $false$ then the tree already contains this $key$ and $false$ is returned.
If the flag is $true$ then the $value$ of the node is updated and $true$ is returned.
Otherwise if the $key$ of the node returned is not equal to $key$ the appropriate child pointer is read transactionaly.
If the value is not $\bot$ then the $find$ procedure is performed again from this node.
Otherwise a new node is allocated and added to the tree using transactional writes.

{\bf Delete} The delete operation does not remove a node from the tree, instead it just marks the node to be deleted later by setting the $deleted$ flag to $true$.
Similar to the other operations, the $find$ procedure is used in order to locate the node to be deleted.
Once the node is found a transactional read is done on $removed$ and $deleted$.
If $removed$ is $true$ the $find$ procedure is performed again.
Otherwise if $deleted$ is $true$ then the operation returns $false$, if $deleted$ is $false$ it is set to $true$ and the operation returns $true$.
If the $find$ procedure does not return a node with the same $key$ as the one being searched for a transactional read is performed on the pointer to where the node with the same key would be.
If the value is $\bot$ then $false$ is returned, otherwise the $find$ operation is executed again starting from this node.


\section{Correctness Proof}

%\subsubsection{Linearisability}
Here we will give a sketch of the proof of the linearizability of these operations.
Without rotations and removals and with the help of transactional reads writes it is easy to show the linearizability of these operations.
First note that the linearizability of the transactional reads and writes is ensured by the TM system.
Also note that in a binary tree structure there is exactly one place where a node with a given key could exist.
It is then only necessary to show that the correct location in the tree is always reached, and that the transactional read/write sets contain enough to ensure the operations are linearizable.

Out of these operations the only one that modifies the structure of the tree is the $insert$ operation, but an insert does not invalidate a search.
The search might have to continue further down the tree in the case of concurrent inserts, but it does not have to abort or roll back, this means that the find operation will always be on the correct path towards the key it is searching.
The result of the $search$, $insert$, and $delete$ operations depend on if the node with the $key$ being searched for is in the tree.
If they find the node with the correct $key$ in the tree then they transactionaly read (and possibly write) $deleted$ field of this before returning, and the linearizability of this is guaranteed by the TM.
Otherwise if the node is not found then the pointer that would point to this node is read (and possibly written to) transactionaly which is again guaranteed to be linearizable by the TM.


\section{Complexity Analysis}
%\subsection{Maintenance Procedures}

In order to keep the tree balanced and to remove nodes marked for removal maintenance must be performed on the tree.
We call this maintenance because it is something happening invisibly to the user or programmer.
The following operations are used for maintenance, $remove_node$, $check_rotation$, $left\_rotate$, $right\_rotate$, $left\_right\_rotate$, $right\_left\_rotate$, $left_propogate$, $right_rotate$.
The rotation and propagate operations are similar to the ones used in \ref{IRISAppr} and \ref{BCCO10}.
Rotations in the classic AVL and red-black tree algorithms are performed along with insert and delete operations.
A single delete or insert operations could entitle rotations going from the point of insertion/deletion all the way up to the root node.
Classical binary tree algorithms do this in order to ensure the tree is strictly balanced.
Unfortunately doing this creates a large amount of contention in parallel executions.
The rotations and propagations here are all executed separately each as their own operations, reducing the contention, but allowing the tree to become unbalanced.
Fortunately, performing these operations repeatedly will eventually result in a balanced tree \ref{IRISAppr}.

{\bf remove\_node} Nodes can be removed from the tree when they have at most $1$ child and their deleted flag is marked to $true$.
A node cannot just be directly removed because there could be a concurrent $search$, $insert$, or $delete$ operations that is preempted on the node.
If the node was simply removed one of these preempted operations might not reach the correct location in the tree.

To prevent this the $remove\_node$ operations works as follows.
First using transactional reads the node is verified to have at most $1$ child.
The operation then performs a transaction write on the parent so that instead of pointing to the node to be removed it points to the node's child (or $\bot$ if the node has no child), effectively removing the node from the tree.
Instead of just committing here the transaction then performs writes on both of the node being removed's child pointers so that they point to the node's parent.
By having these pointers point to the parent ensures that preempted operations are able to reach the correct location in the tree when using $unit$ reads.

{\bf left\_propagation} The propagation is used to propagate changes of the height of the tree from leaf nodes up to the root.
When a node is inserted or removed from the tree it could effect the height of the left and right subtrees from the point of the insertion all the way up to the root.
This height information is necessary in order to perform the appropriate rotations.
Since the goal is to reduce conflicts the propagation operation is as small as possible with each operation executing at a single node and its left or right child.
The basis of this operation is that when a node has no left/right child it knows that the height of its left/right subtree is $0$, and this information is propagated up the tree with the height of the parent being $1$ greater then its child.
The $left\_propogation$ takes as input a single node $nodoe$ and starts by performing a transactional read on $removed$ to ensure that $n$ is still in the tree.
Next the $lefth$ field of node is read transactionaly into the local variable $lefth$, if the value is $0$ then the node has no left child and the operation is complete.
If the value is greater than $0$ then $n$'s $left\_child$ pointer is read transactionaly into the local variable $child$ (note that it is not necessary to read the value of
$removed$ for $child$ because if $n$ is not removed then its child is necessarily still in the tree).
The $localh$ variable of $child$ is then read transactionaly into the local variable $child\_localh$.
If $lefth$ and $child\_localh$ are equal then no changes are necessary and the operation is complete.
Otherwise $node.lefh$ is updated using a transactional write to the value of $child_localh$.
Finally the value $node.localh$ is updated to be $1 + \max(child\_localh, node.right\_height)$ as necessary using transactional reads/writes.
The $right\_propogation$ procedure is omitted here as that it is the mirror of the $left\_propogation$ procedure.

{\bf check\_rotation} The $check\_rotation$ procedure takes as input a node $n$ and its parent $p$.
First the $removed$ flag is read for both the $p$ and $n$, if the $removed$ flag is set to $true$ for either node then $false$ is returned and no rotations are performed on these nodes.
If the $removed$ flag is $false$ for both nodes then the procedure continues.


\section{Discussion}

\subsection{Increasing concurrency by doing less work}
\subsubsection{Being Lazy}
Sometimes it is good to be lazy.
Consider deletion, in a classic AVL or red-black tree, deleting a node might require removing the node, finding the successor, moving the successor to its new place and performing
some amount of rotations.
Performing this in a concurrent context while ensuring linearizability of all operations requires creating possibly a large amount of conflicts.
In a concurrent context it might make more sense to just mark the node as deleted.
This creates a single point of conflict.
A concurrent search operation will not even conflict with this, as that unless it is searching for the `key' value of the node, it does not care whether
the node has been marked as deleted.
Moreover, rotations will not be required as that the structure of the tree has not changed, and a later insert operation of the same `key'
value only need to unmark the node as deleted, again allowing for more concurrency.

Being lazy and just marking nodes as deleted will leave extra, unnecessary nodes in the tree.
At first thought one might consider these extra nodes to be harmful as that they will require the search operations to traverse more nodes then in the optimal case.
This is true, but is not necessarily always bad.
Let us consider a specific example.

A workload that has high contention is executed on a tree, performing many concurrent operations, performing a similarly high amount of inserts and deletes.
This leaves the tree at more or less a constant size throughout the workload, for example a size $100$ nodes.

If executed by a non-lazy algorithm the tree will be kept at around the same size with no marked deleted nodes throughout the workload.
If there are multiple threads running this leaves the tree under very high contention.

Now if the workload is executed by an algorithm that is a bit lazier which allows the tree to grow larger than $100$ but only by a constant factor, say for example $200$.
This means that each search operation might have to travel through a few extra nodes to reach its destination (at most $\log(200) - \log(100)$ extra nodes if the tree is balanced, which is $1$).

First consider that the operations are mostly performed on the same $100$ values, this means that half the nodes in the $200$ node tree will rarely be modified or searched for.
Even though this is true, having the tree twice as large reduces contention.
For example consider that the node with value $31$ is a leaf in the $100$ ndoe tree, and two inserts are preformed concurrently with values $34$ and $37$, with each value to be inserted to the right
of the node with value $31$, in this case the two inserts would conflict and one would have to be inserted after the other.
Now consider the tree with $200$ nodes, it might have an additional node with value $36$ already in the tree, now $34$ is inserted to the left of this node and $37$ to the right, allowing both inserts to
execute concurrently.

More likely than only accessing a range of $100$ the workload will frequently perform operations on a much larger range of values.
First for simplicity consider this range to be $200$.
In this case every insert and delete in the lazy algorithm will just perform a single write marking or unmarking the deleted status of the node.
The non-lazy algorithm on the other hand will be constantly removing and adding nodes and performing rotations creating much more contention.

Finally consider the range to be much larger, for example $2000$.
The lazy algorithm will now be removing and inserting nodes, but it has twice as many locations to do so compared to the $100$ node tree.

With the lazy algorithm, operations are slightly more expensive, but depending on the workload and how many concurrent operations take place at a time
contention could be greatly reduced, or even practically eliminated.
Contention leads to aborts, and aborts are expensive especially if the transactions are large or contain multiple nested operations on the tree, in comparison to this, traversing
thorough a small amount of extra nodes just requires a few extra unit loads which has very little cost.
Of course this all depends on the workload, but even if contention is not lowered from increasing the size of the tree, the extra cost is small.

Deletions are not the only place it can be beneficial to be lazy.
Rotations can also be performed lazily.
Inserting or removing nodes from the tree will require rotations to keep the tree balanced.
But due to concurrent operations that balance is always changing.
An insert might require a node to be rotated to the right while a concurrent insert on another part of the tree might then be required to rotate the same node to the left.
Often concurrent operations will create conflicting rotations, or even balance each other out.
It might not be necessary to perform all rotations every time the structure of the tree is changed.
Similar to having a small amount marked deleted nodes in the tree, having the tree be partially unbalanced means certain operations might have to travers a few extra nodes, but
often saves wasted work and reduces conflicts.

\subsubsection{Not being too lazy}
As described in the previous section being lazy can be beneficial for concurrent data structures, but being too lazy can have negative consequences.
If nodes are just marked as deleted and not removed from the tree often enough, the number of marked deleted nodes can grow to be much larger than the
number of non-deleted nodes resulting in poor performance of the search operation.
The same is true with rotations, if rotations are performed too lazily, the tree can become unbalanced, again resulting in poor performance of the search operation.

This highlights a crucial trade off between eagerness and laziness.
There are two extremes, on one end is the classic AVL and red-black trees which ensures the structure is always perfectly balanced and contains no unnecessary nodes, on the other end is a completely
lazy implementation which never performs rotations and only marks nodes as deleted.
Depending on the workload the most efficient solution can be closer to one extreme then the other.
When operations are performed asynchronously by concurrent threads the most efficient solution may change throughout the workload,
but because the threads are asynchronous and the future is not known it is impossible to predict the optimal solution.
For example at one point during the execution there might be several threads performing operations often on the tree creating a lot of contention
while later during the execution there might just be a single thread executing operations on the tree, whith each case benifiting from a different amount of laziness.

\subsubsection{Determining the right amount of laziness}
A single thread does not know what operations on the tree it will execute in the future, let alone the current or future actions of other thread,
so it can only guess as to what to do in order to be the most efficient.

\ref{BCCO10} takes a more active approach on the rotations and a more intermediate approach for the deletions.
The general idea is that after a thread performs an insertion or deletion the thread then travels up the tree performing propagations and rotations
as necessary.
Nodes are removed from the tree when a deletion is performed and they have at most $1$ child.

Here we take a more varied approach.
The goal is for the tree to be provided as a library to be used within a transaction.
This means that likely multiple operations on the tree will be nested within a single transaction and within the transaction
the programmer will likely be performing other operations on separate data and, because of this, aborting a transaction can be very expensive.
To reduce aborts the read/write set should be kept as small as possible, but still insure the correctness (linearizability) of the operations.
This means that within the transaction no search/insert/rotate should ever perform a rotation, and a delete only perform a marked
delete within the transaction.

If not within the insert/delete transactions, rotations and removals need to be done somewhere in order to keep the search operations efficient.
Instead having the application threads perform the rotations a separate thread is created, called the maintenance thread that takes care of these operations.
This thread continually travels throughout the tree performing propagations, rotations, and removals.
There were several reasons to perform these operations on a separate thread.
Firstly the most common maintenance operation is the propagation, and this operation uses its own variables so it
will never conflict with a search/insert/delete operation allowing it to run concurrently with the application threads.
Secondly the application threads should be able to execute as fairly as possible.
If an application thread gets unlucky it might get stuck performing lots of rotations, slowing down its progress, which becomes even worse in the
case that other application threads depend on it.
If all the cores of computer are in use then the operating system will be able to share the processing time between the cores allowing the maintenance to be done
more fairly then by trying to do it directly in the application threads.
Thirdly since computers are expected to be shipping with increasing number of cores some of them might be not used by application threads, letting the
maintenance be executed on its own thread.

Executing the maintenance in a separate thread still does not solve the problem of deciding how lazy to be.
In order to do this several mechanisms are used.
As the maintenance thread travels the tree, if it finds that less then some percentage of nodes are marked deleted, and it also finds that few rotations are needed
then the maintenance thread will start executing slower by spending a certain ammount of time sleeping.
If more maintenance is found to be needed then the thread will sleep less often.

Each application thread can also influence the amount of maintenance done.
When the thread traverses the tree during a search/insert/delete if it finds more then a certain percentage of marked deleted nodes, then it will set a flag.
Part of the maintenance thread's operation is to check these flags, which will then effect the amount of sleep time chosen.
This way if the application threads are not modifying the tree then the maintenance thread will not run unnecessarily.

A third mechanism is used in order to ensure that the tree does not grow too large with marked deleted nodes.
If the maintenance thread finds more then a certain percentage of nodes are marked deleted nodes then it will set a flag letting the application threads know that it needs help
to prevent the tree from growing too large.
When this flag is set application threads will remove nodes from the tree during their delete operation if the node has at most $1$ child.
The removal can be done in the same transaction to increase the chance the node will be removed, or in a separate transaction to minimize the size of the read/write set of the
original transaction.


\section{Experimental Evaluation}

\section{Conclusion}

\subsection*{Acknowledgements}
This work is supported in part by the European Commission FPS under grant numbers 216852 and 248465.
{\bf TODO: Acknowledge TransForm.}


\bibliographystyle{plain}
\bibliography{bib}

\end{document}


